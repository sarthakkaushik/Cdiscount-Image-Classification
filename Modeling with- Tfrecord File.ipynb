{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reading- Tfrecord File.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNMfehBoTFjwonTElfwlk8a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthakkaushik/Cdiscount-Image-Classification/blob/main/Modeling%20with-%20Tfrecord%20File.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "m4RzjsSUdfhl",
        "outputId": "8cf4f829-3775-4792-aa85-ccdf499a1b30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 15 05:19:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0U2Q4JK0zak",
        "outputId": "2ca12bc0-0fd7-4b9f-9e66-a5020006e0ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Code to mount google drive in case you are loading the data from your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "data_path = '/gdrive/MyDrive/UOH Assignment Dataset/cdiscount'\n",
        "os.chdir(data_path)\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyZm7UQO05Aq",
        "outputId": "366ef816-52f9-4f96-d0f3-4c0be43704bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/UOH Assignment Dataset/cdiscount\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, math, io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing as mp\n",
        "import bson\n",
        "import struct\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread \n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import tensorflow as tf\n",
        "\n",
        "from collections import defaultdict\n",
        "from tqdm import *\n",
        "from tensorflow.python.data.experimental import AUTOTUNE\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../cdiscount\"]).decode(\"utf8\"))\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcgbCYmS0-TN",
        "outputId": "475be656-6cfa-48fb-97d5-ce6702ba5fd0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "categories.csv\n",
            "category_names.csv\n",
            "CheckPoints\n",
            "file.h5\n",
            "helper.py\n",
            "helper.py.1\n",
            "helper.py.2\n",
            "helper.py.3\n",
            "helper.py.4\n",
            "helper.py.5\n",
            "helper.py.6\n",
            "helper.py.7\n",
            "helper.py.8\n",
            "helper.py.9\n",
            "output_data\n",
            "__pycache__\n",
            "sample_submission.csv\n",
            "Tensorboard\n",
            "test.bson\n",
            "test_TFrecords.tfrecords\n",
            "train.bson\n",
            "train_example.bson\n",
            "train_images.csv\n",
            "training_logs\n",
            "train_offsets.csv\n",
            "train_TFrecords.tfrecords\n",
            "val_images.csv\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for raw_record in raw_dataset.take(10):\n",
        "#   print(repr(raw_record))"
      ],
      "metadata": {
        "id": "GNuPdGkR2uu3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for raw_record in raw_dataset.take(1):\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(raw_record.numpy())\n",
        "  print(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "IdJZY48p41Uw",
        "outputId": "4060b0c1-647a-4d81-ba5f-e18ee9e5c138"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5359b2b84d01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mraw_record\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'raw_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Understanding the Tfrecord Data"
      ],
      "metadata": {
        "id": "d3wsDIq85Ugg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading Tfrecord file\n",
        "import IPython.display as display\n",
        "\n",
        "data_dir = \"../cdiscount/\"\n",
        "\n",
        "train_tfrecord_path = os.path.join(data_dir, \"train_TFrecords.tfrecords\")\n",
        "\n",
        "\n",
        "raw_dataset = tf.data.TFRecordDataset(train_tfrecord_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#############################################################################################\n",
        "\n",
        "from PIL import Image\n",
        "def parse_tfr_element(element,img_shape=180):\n",
        "  #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
        "  data = {\n",
        "      'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "      'width':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'depth':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'category_id':tf.io.FixedLenFeature([], tf.int64),      \n",
        "      'product_id':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'img_raw' : tf.io.FixedLenFeature([], tf.string)\n",
        "          }    \n",
        "  return tf.io.parse_single_example(element, data)  \n",
        "\n",
        "parsed_image_dataset = raw_dataset.map(parse_tfr_element)\n",
        "parsed_image_dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "########################################################################################\n",
        "\n",
        "for image_features in parsed_image_dataset:\n",
        "  print(\"Type of image_features\",type(image_features))\n",
        "  print(\"Type of image_features-Img_raw\",type(image_features['img_raw']))\n",
        "  image_raw = image_features['img_raw'].numpy()\n",
        "  print(\"Numpy_array-\",image_raw)\n",
        "  display.display(display.Image(data=image_raw))\n",
        "  print(\"Category ID\",image_features['category_id'],\"\\nProduct ID-\",image_features['product_id'],\"\\nHeight-\",image_features['height'],\n",
        "        \"\\nWeidth-\",image_features['width'],\n",
        "        \"\\ndepth-\",image_features['depth'])\n",
        "  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "F4s6VFXq5WCl",
        "outputId": "623bbe12-5471-4c54-8817-bbdcab5b5776"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of image_features <class 'dict'>\n",
            "Type of image_features-Img_raw <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "Numpy_array- b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x08\\x06\\x06\\x07\\x06\\x05\\x08\\x07\\x07\\x07\\t\\t\\x08\\n\\x0c\\x14\\r\\x0c\\x0b\\x0b\\x0c\\x19\\x12\\x13\\x0f\\x14\\x1d\\x1a\\x1f\\x1e\\x1d\\x1a\\x1c\\x1c $.\\' \",#\\x1c\\x1c(7),01444\\x1f\\'9=82<.342\\xff\\xdb\\x00C\\x01\\t\\t\\t\\x0c\\x0b\\x0c\\x18\\r\\r\\x182!\\x1c!22222222222222222222222222222222222222222222222222\\xff\\xc0\\x00\\x11\\x08\\x00\\xb4\\x00\\xb4\\x03\\x01\"\\x00\\x02\\x11\\x01\\x03\\x11\\x01\\xff\\xc4\\x00\\x1f\\x00\\x00\\x01\\x05\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\xff\\xc4\\x00\\xb5\\x10\\x00\\x02\\x01\\x03\\x03\\x02\\x04\\x03\\x05\\x05\\x04\\x04\\x00\\x00\\x01}\\x01\\x02\\x03\\x00\\x04\\x11\\x05\\x12!1A\\x06\\x13Qa\\x07\"q\\x142\\x81\\x91\\xa1\\x08#B\\xb1\\xc1\\x15R\\xd1\\xf0$3br\\x82\\t\\n\\x16\\x17\\x18\\x19\\x1a%&\\'()*456789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\x83\\x84\\x85\\x86\\x87\\x88\\x89\\x8a\\x92\\x93\\x94\\x95\\x96\\x97\\x98\\x99\\x9a\\xa2\\xa3\\xa4\\xa5\\xa6\\xa7\\xa8\\xa9\\xaa\\xb2\\xb3\\xb4\\xb5\\xb6\\xb7\\xb8\\xb9\\xba\\xc2\\xc3\\xc4\\xc5\\xc6\\xc7\\xc8\\xc9\\xca\\xd2\\xd3\\xd4\\xd5\\xd6\\xd7\\xd8\\xd9\\xda\\xe1\\xe2\\xe3\\xe4\\xe5\\xe6\\xe7\\xe8\\xe9\\xea\\xf1\\xf2\\xf3\\xf4\\xf5\\xf6\\xf7\\xf8\\xf9\\xfa\\xff\\xc4\\x00\\x1f\\x01\\x00\\x03\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\xff\\xc4\\x00\\xb5\\x11\\x00\\x02\\x01\\x02\\x04\\x04\\x03\\x04\\x07\\x05\\x04\\x04\\x00\\x01\\x02w\\x00\\x01\\x02\\x03\\x11\\x04\\x05!1\\x06\\x12AQ\\x07aq\\x13\"2\\x81\\x08\\x14B\\x91\\xa1\\xb1\\xc1\\t#3R\\xf0\\x15br\\xd1\\n\\x16$4\\xe1%\\xf1\\x17\\x18\\x19\\x1a&\\'()*56789:CDEFGHIJSTUVWXYZcdefghijstuvwxyz\\x82\\x83\\x84\\x85\\x86\\x87\\x88\\x89\\x8a\\x92\\x93\\x94\\x95\\x96\\x97\\x98\\x99\\x9a\\xa2\\xa3\\xa4\\xa5\\xa6\\xa7\\xa8\\xa9\\xaa\\xb2\\xb3\\xb4\\xb5\\xb6\\xb7\\xb8\\xb9\\xba\\xc2\\xc3\\xc4\\xc5\\xc6\\xc7\\xc8\\xc9\\xca\\xd2\\xd3\\xd4\\xd5\\xd6\\xd7\\xd8\\xd9\\xda\\xe2\\xe3\\xe4\\xe5\\xe6\\xe7\\xe8\\xe9\\xea\\xf2\\xf3\\xf4\\xf5\\xf6\\xf7\\xf8\\xf9\\xfa\\xff\\xda\\x00\\x0c\\x03\\x01\\x00\\x02\\x11\\x03\\x11\\x00?\\x00\\xf7\\xfa(\\xa2\\x80\\n(\\xa2\\x80\\n(\\xac\\xfd{Pm\\'\\xc3\\xfa\\x8e\\xa2\\xab\\xb9\\xadm\\xa4\\x98/\\xa9U$\\x0f\\xd2\\x809\\xdf\\x13\\xfc@\\x83E\\xd5\\x17E\\xd2\\xf4\\xf9\\xf5\\x9dm\\x93y\\xb4\\xb7`\\x04K\\xfd\\xe9\\x1c\\xf0\\xa3\\xf5\\xac\\xa1\\xe2\\xff\\x00\\x1f\\xe3\\xfeD\\xcd;\\xff\\x00\\x06\\xeb\\xff\\x00\\xc4\\xd6\\x1e\\x83%\\x9f\\x83\\xfe\\x1d\\xcb\\xe2\\x8d@\\x9b\\x8b\\xdb\\xd8V\\xfe\\xf2l|\\xf3\\xc9&\\n\\xa6}2\\xc0\\x0f\\xc4\\xd7\\x9dK\\xe3?\\x1aj\\xae\\xba\\x84\\xbe\"\\x8fE\\xb5\\x9f&\\x08c\\x8c\\x90@88UVb\\x01\\xe3q\\xef\\x9cP=:\\x9e\\xc5\\xff\\x00\\tw\\x8f\\xff\\x00\\xe8L\\xd3\\xbf\\xf0p\\xbf\\xfcM\\x03\\xc5\\xbf\\x10\\x0f\\xfc\\xc9zw\\xfe\\x0e\\x17\\xff\\x00\\x89\\xaf\\r\\xbe\\xf1\\x7f\\x8e\\xb4\\xf7\\x8f\\x7f\\x8a.$\\x8aU\\xdd\\x14\\xd1\\x15d\\x90\\x03\\x83\\x83\\x8e\\xa0\\xf0A\\xc1\\x15\\x7f\\xc3\\xbf\\x16\\xbcE\\xa4\\xea\\x10\\xb6\\xafzu=8\\xb7\\xef\\xd6D_1T\\xff\\x00\\x12\\xb0\\x1d\\xba\\xe0\\xd0=\\x0fd\\xff\\x00\\x84\\xb3\\xe2\\x07\\xfd\\tzw\\xfe\\x0e\\x17\\xff\\x00\\x89\\xa3\\xfe\\x12\\xcf\\x88\\x1f\\xf4%\\xe9\\xdf\\xf88_\\xfe&\\xbaX$\\x8e\\xe6\\xde9\\xe1p\\xf1J\\x81\\xd1\\xc7FR2\\x0f\\xe5O+S\\'b\\xd4\\x11\\xcb\\x7f\\xc2[\\xf1\\x03\\xfe\\x84\\xbd;\\xff\\x00\\x06\\xeb\\xff\\x00\\xc4\\xd1\\xff\\x00\\tw\\x8f\\xff\\x00\\xe8K\\xd3\\xbf\\xf0n\\xbf\\xfcMt\\xe5i\\xa5k\\x9eu\\xa4\\xb65Tbs?\\xf0\\x97\\xf8\\xfb\\xfe\\x84\\xcd?\\xff\\x00\\x06\\xeb\\xff\\x00\\xc4\\xd4r|B\\xf1N\\x95\\x8b\\x9dk\\xc1dX/\\xfa\\xd9t\\xfb\\xd5\\xb8x\\xc7\\xf7\\xb6`dWNV\\x9aV\\xb0\\xfa\\xd4\\xd3\\xd8\\xaf\\xab\\xc1\\x9a\\xfa6\\xb5\\xa7\\xf8\\x83J\\x83S\\xd3.R\\xe2\\xd2u\\xdc\\x8e\\xbf\\xa8#\\xb1\\x1d\\xc1\\xab\\xf5\\xe6^\\x1a\\xb4o\\r|M\\x9bN\\xb1\\x02=+X\\xb3\\x92\\xf0\\xdb\\xaf\\x0b\\x1c\\xf1\\xb2\\xab2\\x8e\\xdb\\x83\\x0c\\xd7\\xa6\\xd7|$\\xa7\\x15$r\\xca<\\xae\\xcc(\\xa2\\x8a\\xa2B\\x8a(\\xa0\\x02\\x8a(\\xa0\\x02\\x8a(\\xa0\\x02\\x8a(\\xa0\\x02\\xb0\\xbck\\xff\\x00\"6\\xbd\\xff\\x00`\\xf9\\xff\\x00\\xf4\\x03[\\xb5\\x85\\xe3_\\xf9\\x11\\xb5\\xef\\xfb\\x07\\xcf\\xff\\x00\\xa0\\x1a\\x00\\xf1\\xaf\\x145\\xd5\\xe7\\xc0\\x9bV6\\xc5!\\xb7\\x86\\xcb\\xe6\\xef\\x80\\x14\\x16\\xfar9\\xf7\\xaf>[;\\xadB\\xce\\xda\\xea\\xc9$\\xba\\x8cB\\x90\\xc8\\xb1.\\xf6\\x85\\x97#iQ\\xc8\\x07\\xa8=\\x0e}k\\xd9\\xfc,n/l\\xf4M2\\xfe\\xde&\\xd3\\xa7\\xd0\\xe3\\x057nY\\x14\\xa2\\x03\\xbb\\xd0\\xf4\\xfaW)\\x17\\xc1+mJY\\xae\\xf4/\\x12Mkg\\xe6\\xba$s[ot\\xc1\\xc1\\x1b\\x83\\x0c\\x8a\\xca\\x9dNm:\\xea\\x0eJOk\\x1ey\\xaa\\xa3X\\xda\\xdaZ\\xdc\\x1f\\xf4\\x813O%\\xbf\\x19\\x88\\x10\\x00\\r\\xe8\\xcd\\x8c\\xe3\\xb0\\x03=j?\\x13\\xea\\xf6\\xda\\xb3C%\\xbc/\\x18\\x8a\\xdf\\xcbvuU.\\x7f\\xe0<W\\xa4\\x0f\\xd9\\xf6\\xef\\xfe\\x86\\xb4\\xff\\x00\\xc0\\x0f\\xfe\\xce\\xb6\\xbc5\\xf06\\xcbJ\\xd5b\\xbd\\xd5\\xf5f\\xd5\\x16\\x16\\x0f\\x1d\\xb8\\x83\\xcaB\\xc3\\xa6\\xeeNG\\xb5j\\t\\x1d\\xd7\\x84-f\\xb4\\xf0f\\x89op\\x08\\x9a;\\x18U\\xc1\\xeb\\x9d\\xa2\\xb6\\xf6\\x1fJ\\x93o4\\xecT\\xc8\\xd9h@c8\\xa6\\xf9d\\xd5\\x9d\\xb4\\x85k\\x9aQ\\xb9\\xa2\\x91P\\xa50\\xad\\\\d\\x06\\xa1e\\xc5s\\xca\\x06\\x8aG6\\x06>)\\xe8\\x7f\\xf6\\x0b\\xbc\\xff\\x00\\xd0\\xe1\\xae\\xfa\\xb86\\x18\\xf8\\xa9\\xa1\\x7f\\xd8.\\xf7\\xff\\x00C\\x86\\xbb\\xca\\xee\\xa2\\xadM\\x1c\\xb5u\\x9b\\n(\\xa2\\xb53\\n(\\xa2\\x80\\n(\\xa2\\x80\\n(\\xa2\\x80\\n(\\xa2\\x80\\n\\xc2\\xf1\\xaf\\xfc\\x88\\xda\\xf7\\xfd\\x83\\xe7\\xff\\x00\\xd0\\rn\\xd6\\x17\\x8d\\x7f\\xe4F\\xd7\\xbf\\xec\\x1f?\\xfe\\x80h\\x03\\x83\\xf0D\\xff\\x00i\\xf0\\x8e\\x8c\\x88\\xa8.\\xed\\xac\\xd1\\x15\\xc9\\xe4\\x82\\xa3\\x8f\\xa61\\xf9\\n\\xebl\\xaf\\xe3\\xb5\\xba]9\\xad\\xde4\\x08\\\\:/\\xc8\\xa79`}\\xf2I\\xaf1\\xd2\\xaf\\x9a\\xdb\\xc0\\xdaI\\x80\\xc9\\r\\xdcv\\xf1\\xb1h\\xcf\\x12\\xa1Q\\xc1\\xef[^\\x06\\xd4e\\xd4o\\xee\\x13SL\\xe2&ky%|\\x186\\xe3\\x00z\\x13\\x9f\\xaf\\x15\\xc5K\\x14\\x9b\\xf6ik\\xdc\\xea\\x9c\\'Q\\xb9S\\x85\\xa3\\xbd\\xfa\\x1dn\\x93\\xe2\\x84\\xbe\\xd5&\\xd3n\"\\xf2\\xee\\x16v\\x8d\\n\\xf2\\xa4\\x01\\x91\\xf8\\xd7I\\x8a\\xf3]&\\x0b\\xb9|h\\xba\\x84v\\xc9q1\\x06Y\"G\\x11\\xa88\\n[\\x9f\\xaf\\x03\\xd6\\xba!\\xae\\xea\\x03\\xc6\\xbfcUW\\xd3\\xe4\\xb5\\xf3\\x11N\\x15\\xb2\\x08\\x07\\x1f\\xed\\x03\\xbb+\\xedJ\\x85w\\xc9y\\xeb\\xad\\x8e~I\\xc2\\\\\\x92\\xd5\\x9dHZ6\\xd4Q\\xde\\xda\\xca\\xe5\\x16t\\xde:\\xa18#\\xf04\\xc9\\xef\\xe2\\x82\\xee;V?\\xbd\\x91IQ\\xfe~\\x95\\xd1*\\xb0\\xb5\\xeej\\xa3+\\xda\\xc5\\x8c\\x1aLUm7PMB\\xd9\\xa5\\x0b\\xb7k`\\xfaR\\xdaj\\x16\\xf7\\xf7\\x17\\x11\\xdb:\\xca\\x90\\x10\\x8f\"\\x9c\\x8d\\xfdv\\x8f\\xa0\\xfeu\\x9cg\\x19\\xc5J;1\\xb8\\xca-\\xa6\\xb6\\'\"\\xa3|b\\xa7\"\\xa1a\\x83S!\\xc4\\xe6%\\x18\\xf8\\xa9\\xa1\\x7f\\xd8.\\xf7\\xff\\x00C\\x86\\xbb\\xaa\\xe1\\xa6\\xff\\x00\\x92\\xa9\\xa1\\x7f\\xd8.\\xf7\\xff\\x00C\\x86\\xbb\\x9a\\xe8\\xa5\\xf0#\\x1a\\x9f\\x13\\n(\\xa2\\xb4 (\\xa2\\x8a\\x00(\\xa2\\x8a\\x00(\\xa2\\x8a\\x00(\\xa2\\x8a\\x00+\\x0b\\xc6\\xbf\\xf2\"\\xeb\\xdf\\xf6\\x0f\\x9f\\xff\\x00@5\\xbbX^5\\xff\\x00\\x91\\x17^\\xff\\x00\\xb0|\\xff\\x00\\xfa\\x01\\xa0\\x0f\\x18\\xd3-\\xae/t\\x8d\\x0e\\x0bv\\xf9\\xda\\xd2\\x15\\xda\\xc7\\x00\\x8d\\x83\\xf9W\\xa1\\xf8cM\\xb6\\xd0\\xed\\'\\x8a}\\xb71\\xdc\\xfc\\xd3\\x16L2\\xa8\\xe0|\\xbd\\xd4s\\x9cr:\\xf4\\xe9\\xe7\\x1a|\\x97\\xda~\\x89\\xa0\\xea\\x11\\xac>Z\\xdbF\\x7fx\\xa4\\xee\\x021\\xc8\\x19\\xf5=kB]GU\\xd6\\xe0\\x8aK\\xb3\\xb6\\x14\\x93q\\x95\\x17k\\x80{\\x0f@+\\xc8\\xc3\\xca\\x9d8\\xb9K\\xe2\\xbb>\\x97\\x1d\\x1a\\xf50\\xca\\x14~\\x14\\x96\\x9egQt48...lu\\x1b\\x95+\\xb7\\x06\\xdeV\\x8d\\xe3\\x00\\x1c\\xa0\\xcf\\xde\\x07\\xa8\\xceFT\\x03\\xd4W<<C|5\\t\\xad\\xeeg\\x86\\xfa\\xde\\xe0n/2m\\x95v\\xfd\\xd6\\x0c\\xb8\\xf9\\xb9\\xebX\\xd7\\x92\\\\\\x16\\xf2 G\\xf2\\xd78rI\\x1f\\\\\\xe0f\\xa8\\xe9\\xd63\\xcb\\xa8\\xa8\\xe3;J\\x86`I\\\\\\xe3\\xa7\\xe5X:\\xf5&\\x9a\\xd1-O\\x9fX\\x0c}d\\xeb\\xa4\\xd7/\\xc9\\x9d\\xbd\\xbf\\x89 \\xbc?d\\xd5\\xe13\\xc6\\x06\\x12\\xe1\\x0e%O\\xf8\\x17\\x7f\\xc6\\xa9\\xd9\\xdd\\xea\\x03Y\\x99R\\xe1\\xe6\\xb7\\xb5\\x07m\\xcc\\xa7\\n\\xab\\x83\\xb7$\\xfdzR\\xcf\\xa2Eej&\\xf3K\\x95P\\x1b\\x1c\\x02\\xdd\\xcdY\\xb9\\xd3n\\xed\\x98Ei\\xbaI\\x15Vh\\x99\\xa1\\xde\\x9b\\x88\\xc8\\xca\\x1e\\x0e3Y\\xc6\\x12\\xb2Z\\xbf\\xcc\\xed\\xa1\\x8b\\xad\\x83\\x82U\\xa2\\xa5\\x19+]t\\xff\\x00\\x83\\xfdjiK\\xa9\\xddK\\xa5\\x8d7LI#\\xb4\\t\\xb5\\xe6\\xdawK\\x9e\\xa7>\\xfc\\xd58#\\xbe\\xd34\\xf9-\\xac\\xa7{x\\x98\\xe5\\x82\\x1c\\x1c\\xfdz\\xd4:N\\xb7p\\xe6A<(&Rx\\x1fp}\\x07Q\\xf4\\xad\\xa4\\x92!b\\xcd&\\x0b\\xb9\\xcbm=)\\xb9\\xb4\\xdd\\xa5\\xb6\\xc7\\xa7\\xcf(Z\\x1c\\x8a\\xcfW\\xd4\\xd8\\xf0n\\xa5}\\xa8X\\\\-\\xeb\\x99\\x0c\\x12\\x04I\\x08\\xe5\\x86;\\xfa\\x9a\\xe8\\x1cUm\\x1a\\x0bX\\xb4\\xa8Z\\xcd\\n\\xc5 \\xdf\\x96\\xfb\\xccOsV\\xdcq^\\xaaO\\x91\\\\\\xf1\\xebN2\\xab\\'\\x15es\\x95\\x97\\xfeJ\\xa6\\x85\\xff\\x00`\\xbb\\xdf\\xfd\\x0e\\x1a\\xeek\\x87\\x9cc\\xe2\\xae\\x83\\xff\\x00`\\xbb\\xdf\\xfd\\x0e\\x1a\\xee+\\xa2\\x97\\xc0\\x8eY\\xfcL(\\xa2\\x8a\\xd0\\x80\\xa2\\x8a(\\x00\\xa2\\x8a(\\x00\\xa2\\x8a(\\x00\\xa2\\x8a(\\x00\\xac/\\x1a\\xff\\x00\\xc8\\x8d\\xaf\\x7f\\xd8>\\x7f\\xfd\\x00\\xd6\\xedax\\xd7\\xfeDm{\\xfe\\xc1\\xf3\\xff\\x00\\xe8\\x06\\x80<SO\\xb3\\x9e\\xff\\x00\\xc26\\xb7\\x17RyqC\\xa7G\\xb4\\x93\\xf2\\xe0(#\\xf9t\\xf55\\xadk~E\\x82\\x14\\xb6f\\x0e\\xa4\\xa6\\xd1\\xf7\\xd3\\xa9#\\xf0\\xaev)-n<3\\xa4C-\\xec\\xc4\\x0bh\\x83Z\\xc6\\xfcI\\xf2\\x8c\\xe4v\\x03\\xf35\\xbdc4i\\xa5\\x0b{tH_hT\\xe3\"2{\\x81\\xed\\x93_7U\\xdb~\\xef\\xee>\\xa2\\x0e\\xac\\xa0\\xd4c\\xa2J\\xc5}\\x03U\\x8b\\\\\\x92\\xe9M\\xb3A\\x0c\\x03y$g\\x8e\\xc3\\xda\\xa5\\xbaP\\x81n L!P\\xcawm\\xf5\\xe2\\x93E\\xd1\\xf4\\xeb\\tn\\x9ex\\xe4wF\\xdb\\x1c\\x8e\\xe7,\\xa4rx\\xf7\\xa4\\xd45\\x08\\xacb\\x8d\\x17\\xe6\\x88\\x0c \\'\\xb7\\xf5\\xac\\xe7({_\\xdc\\xad\\x0ezx\\xaa\\xf4):\\x98\\x87h\\xfe-\\x9dN\\x8f\\x1c\\xd7>L\\xf2\\xcf\\x15\\xcd\\xab\\xc4\\xac\\x9b\\x90\\xab)\\xf7\\x07\\x8c\\x8e\\x99\\xad\\xb1\\x14\\xcb\\xab)L\\x98\\xf8<\\x8f\\x94\\x8e\\xe7>\\xb5\\xe6z7\\x8e/t\\xcb\\xd6\\xc6\\x8b\\xa9j\\xb6L\\xb9\\xd9g\\x1eLlO\\x078<\\x10\\x0f\\x15\\xe8\\xb6>!\\x8bZ\\xb470\\xda\\xdfi\\xe5>Y-\\xaf\\xe1\\xf2\\xdcw\\xcf\\xb8\\xf7\\x06\\xbe\\xa3\\x04\\xe3\\xec\\xa3\\x18\\xab7\\xb9\\xe4\\xacS\\xad\\xab\\xeaqZ\\xce\\x93}\\xa6\\xea:\\x85\\xcd\\xb3<\\x96\\xcf(\\x92$\\x07$n\\xce@\\x1dx8\\xfc\\xfe\\xb4\\xdbmNG\\xb77\\',\\x89&\\xd9!l\\x80\\xd8\\xc6@#\\xf2\\xae\\xaa[)\\xb5\\xab\\xd9\\xf5\\x1d\\x1a\\xe9Z\\xce%\\x0b\\xbaD*\\xaf(\\x1c\\xa4g\\xf8\\x86p3\\xd0\\x13\\x8c\\x9e\\xdc$\\x97s\\xebwM\\xa7ZY\\xbd\\xcc\\xd3\\x87O%\\x08\\x07$\\x11\\x9c\\xf4\\x18\\'9\\xed\\x8a\\xf1\\xb14_\\xb7\\xf7c\\xd7s\\xdb\\xc0\\xca.\\x83I\\xddE6\\xfb\\xfa\\x1e\\xe7\\xa7]A{\\xa6[]\\xdb\\x02 \\x9a%x\\xc1\\x18\\xc2\\x91\\xc0\\xa9[\\xa5q\\xff\\x00\\ruY\\xaf|#\\x16\\x9f|\\x82-OIccw\\x17B\\x19>\\xebc\\xd1\\x86\\x0e{\\xf3]k5z\\x12\\xd3C\\xc2Vn\\xe8\\xe6n\\x7f\\xe4\\xaa\\xe8?\\xf6\\x0b\\xbd\\xff\\x00\\xd0\\xe1\\xae\\xde\\xb8\\x8b\\x83\\x9f\\x8a\\x9a\\x0f\\xfd\\x82\\xef\\x7f\\xf48k\\xb7\\xad\\xa9\\xfc(\\xc6\\x7f\\x13\\n(\\xa2\\xac\\x90\\xa2\\x8a(\\x00\\xa2\\x8a(\\x00\\xa2\\x8a(\\x00\\xa2\\x8a(\\x00\\xac/\\x1a\\xff\\x00\\xc8\\x8d\\xaf\\x7f\\xd8>\\x7f\\xfd\\x00\\xd6\\xedax\\xd7\\xfeDm{\\xfe\\xc1\\xf3\\xff\\x00\\xe8\\x06\\x80<\\x03O\\xd2\\x9aM\\x0bO\\x95I\\x0c\\xd6\\xd1\\x90\\xc3\\xb7\\xca+\\xb1\\xf0\\'\\x85\\x0e\\xb4/\\x9a\\xea\\xeaH\\xc5\\xb0U\\x88*\\x8d\\xa5\\x98\\x1e[\\xd7\\x18\\x07\\x15\\x9f\\xe0l\\xea>\\x0e\\xb6\\x9ed \\xc5\\nD\\xa7n\\x06\\xd01\\xf8\\xe6\\xb4\\xb4\\x0b\\xddB\\xd7]\\x8bK\\x96\\xf0Gg{3 \\x8a\\x13\\xb0\\xefn\\x85\\x9b\\xab\\x00\\xa0\\x8c\\x03^%\\x19\\x7f\\xb4:u\\x0f\\xa9\\xc4cgS\\x05\\xfb\\x95\\xae\\x9f$\\x8c\\x1b\\xeb=n\\xd6\\xfc\\xd9\\xa5\\xa4\\xd3\\xc9\\x82c1)a2s\\x86_c\\x8c\\xd4\\xdaF\\xa7qo\\x03\\xc4tk\\x1b\\xe9$\\xc2H\\xd7\\xa0\\x9d\\xa3vx\\x00\\xe3\\x03\\xf3>\\xa2\\xbd\\xd2\\xe2\\x1bx\\xe0y\\xbc\\xa8\\xd5\\x92\\x16P\\xd8\\xc1\\x0b\\x8e\\x99\\xec+\\xc2\\xfc0\\xd2]\\xe8BIa{[\\x81\\x11\\xc8\\x910\\xaaG~\\xbd+LD>\\xac\\xb9\\xe0\\x96\\xe7=\\x1cR\\xc7\\xc1\\xc7\\x12\\xbe\\x15\\xa5\\xb4\\xf9\\xfa\\x9az\\x9e\\xbb\\xe2\\x01h-m\\xae^ \\xc4(\\xfb$\"\\x05\\x03\\x18\\xc9\\x0b\\xd0c\\xa0$\\xfdkC\\xc0:\\xc6\\xad&\\xbc4k\\xf9^\\xf2\\xc6X[\\x0bq\\xf3\\xf9{G\\x18\\xcfc\\xd0\\xfe\\x15\\xcc\\xf8SW\\xbb\\xd4\\xaf.F\\xa0\\x1eH\\xf2|\\xa6\\x8e#\\xb3#\\xa9\\xce1\\xd3\\x15b\\xe3R\\xba\\xf0\\xfe\\xaf\\xfd\\xadgtc1\\xae\\x1a7Q\\xb3o\\xf1g\\xbfO\\xe4*)\\xd6\\xab\\x0cB\\x8dV*\\x14)U\\xa1S\\xd9GW\\xb5\\xfa[\\xfa\\xf9\\x9e\\xbd\\xaej:^\\x97\\xa7\\xff\\x00\\xc4\\xcaE\\xb7\\xb5\\xf2\\xdc\\xab\\xed;Sj\\x93\\xd5z\\x1c\\x02GN\\x87\\x15\\xe1#\\xe3M\\xc7\\xdaZ\\xcfG\\xb2K\\x99e\\x89\\xe0\\x8a\\xea\\xe2\\x14\\x86l\\xff\\x00\\x03\\x12\\x84\\x0cz\\xaf\\x1d\\xb9\\xcd{E\\xcbE\\xe2\\xbf\\x04N$\\x8d\\xa2\\x87R\\xb1\\x7f\\x95\\xba\\x85e8?\\x96\\r|_\\x83\\x1b\\x9c\\x1eT\\xf5\\x15\\xebE^\\xe7\\x85{=Oh\\xb4\\xd7u\\x9bQ\\x16\\xa9\\xaf-\\xc5\\xa5\\xc6\\xff\\x00)\\xef,\\xe4f\\x99\\x01\\xe1HV\\'w\\xcd\\x8c\\xa7*\\xc0\\xf4\\x07\\x9a\\xf6\\xed\\x0e}F}\\x02\\xc2]^$\\x8bRx\\x15\\xae#A\\x80\\xaf\\xdf\\x8e\\xde\\xe3\\xb1\\xcdx^\\x93\\xab(\\xf0Cj\\x9a\\x8d\\xc3^y\\x88\\x8d\\xe5y[\\x99\\x1d\\x0e\\xdc\\xfe\\x80\\xfe}\\xeb\\xde-.V\\xe2\\xd2\\x19\\xc4\\x81\\xc4\\x91\\xab\\x87\\x1f\\xc5\\x90\\x0ek\\x87\\xda\\xc9\\xddK\\xa3\\xdc\\xf4*\\xd2\\x82\\xe5p\\xd2\\xebn\\xbe\\xbf3\"S\\x9f\\x8a\\x9a\\x17\\xfd\\x82\\xef\\x7f\\xf48k\\xb9\\xae\\r\\x8e~*h_\\xf6\\x0b\\xbc\\xff\\x00\\xd0\\xe1\\xae\\xf2\\xbb\\xa9;\\xc1\\x1e}Ei0\\xa2\\x8a+B\\x02\\x8a(\\xa0\\x02\\x8a(\\xa0\\x02\\x8a(\\xa0\\x02\\x8a(\\xa0\\x02\\xb0\\xbck\\xff\\x00\"6\\xbd\\xff\\x00`\\xf9\\xff\\x00\\xf4\\x03[\\xb5\\x85\\xe3_\\xf9\\x11\\xb5\\xef\\xfb\\x07\\xcf\\xff\\x00\\xa0\\x1a\\x00\\xf2?\\x08Xi\\xdaw\\x85,\\'\\x84~\\xfe\\xe2\\xda\\'\\x94\\xe7 \\xb6\\xdfC\\xd3\\xaf\\xe9Z:-\\xa5\\xbe\\xbd\\xe2U\\xb3\\x98\\xb3F\\xa8\\xfb\\x80\\x1c\\xa9(\\xc0\\x1c\\xf6\\xc7\\x04W\\x1d\\xa5\\xeaS\\r#L\\xb6\\x8e3$\\x8d\\x04+\\x12\\x06\\x03{\\x15\\x00\\x0c\\x9e+\\xd9\\xcd\\x84>\\x1f\\xd3L\\xda>\\x9a\\x86\\xe7r\\xbbD\\\\\\xe5\\xff\\x00\\xbc7\\x1c\\x9e\\x84\\xd7\\x8bG\\x0f)\\xd5\\x95i\\xea\\x91\\xefc\\xe4\\xb0\\x98eF;\\xc9k\\xe9\\xff\\x00\\x04m\\xee\\x89\\x7f\\xa5x#Q\\xb0\\xd2\\xeeg\\xb9\\xba\\x91\\tBO\\xcc3\\x8d\\xc1s\\xed\\x9a\\xf2\\xed\\x1e[\\x9b\\xad0\\xcb\\r\\x9c\\xf7\\x16\\xee\\xacC*\\x1d\\x8c\\x17\\x93\\x96<c\\x00\\xe75\\xedV\\xb7\\x12\\xdd\\xe9\\xd1\\xbd\\xd4>D\\x92\\xc7\\xfb\\xc8\\x83\\xe7n{\\x02+\\x82\\x1f\\x0b--\\xa7\\xbbk\\x0f\\x13x\\x82\\xce\\xde\\xe8\\xb1\\x9a\\xda\\x1b\\x85\\xd8\\xdb\\xbe\\xf0<s\\x9c\\x9a\\xef\\xab\\x85\\xa7V)tG\\x06\\x0b\\x1f,59S\\x8cS\\xb9\\x90\\x9a\\xc4\\x16\\xb0H\\xb6\\xfbQ%>f\\x14`n\\xff\\x00\\xf5V\\x8e\\x93\\xe0\\xdb?\\x13\\xdb\\xdbjz\\x9d\\xc1\\x9a\\xc5\\x9bz\\xda *$*q\\xf3\\x93\\xce2:\\x0e\\xbe\\xb4\\xfd?\\xc0Z[xn\\xf2\\xd1|\\xeb\\x8b\\xc8\\xe6\\xb8\\x8a+\\x89\\xa7f,U\\x98&\\xeeq\\x8e\\x00<z\\xd7S\\xa0j\\xb1\\xea\\xba\\x15\\xad\\xd4v\\x92Y\\xfc\\xbe[[H\\x9bL,\\xa7k\\'\\xd0\\x11\\xc1\\xf4\\xc5sQ\\xc1F\\x8c\\x9c\\xdb\\xbb:\\xf1\\x18\\xf8\\xce\\x9a\\xa7Er\\xdfq\\xfe$\\xd4SO\\xf0\\xf6\\xa0c!e\\x16S\\xb4H\\x07\\xf7#\\'\\x8f\\xa7\\x15\\xf1\\x8a\\x86f\\x01A$\\xf6\\x02\\xbe\\xd2\\xbb\\xb5\\xb7\\xbd\\x08\\'@\\xfb\\t\\xc7=\\x8a\\x95a\\xf4 \\x90Ey\\xd4\\x7f\\x08tM>\\xcbP\\x16\\xa8\\xb772H\\x1e\\xd5\\xaeA>R\\x8f\\xf9g\\x9c\\xfd~n\\x0fJ\\xeb\\x8dX\\xc7s\\xcc\\x956\\xf63~\\x16\\xf8^\\xc3V\\xf0d\\xd1j\\xb6\\xd20b\\x01Vb\\xb8\\x07,\\x08\\xc7 \\xf7\\xe0\\xd7i\\xa3\\xdb\\xdcxoX\\x8fC\\x13\\xbc\\xda<\\xd6\\xe5\\xac<\\xd3\\x97\\xb7d\\xc6\\xe8\\x8bwR\\x0e\\xe5\\xcfL\\x11Y\\xb6\\x97\\x91\\xfc>\\xf8q\\x15\\xcd\\xe5\\xac\\xac\\xf0\\x15I\\xd4\\x1c\\xb1%\\xf6\\x82I\\xec\\x06) \\xf15\\x97\\x88\\xf5\\xdd\\x07\\xfb*\\xe8\\xdc\\x85\\x9a{\\x89\\xd7h\\ro\\x18\\x88\\xa8\\x0c\\x07L\\xb3.3\\xd6\\xb9\\xa6\\xdc\\x9b}5:#\\xd2\\xfb\\x9d\\n0o\\x8aZ\\x1f\\xfd\\x82\\xef?\\xf48k\\xd0+\\xce\\xed\\x8e~)h\\xbf\\xf6\\x0c\\xbc\\xff\\x00\\xd0\\xe1\\xafD\\xae\\xbc3\\xbd$\\xceZ\\xea\\xd5\\x18QE\\x15\\xb9\\x90QE\\x14\\x00QE\\x14\\x00QE\\x14\\x00QE\\x14\\x00V\\x17\\x8d\\x7f\\xe4F\\xd7\\xbf\\xec\\x1f?\\xfe\\x80kv\\xb0\\xbck\\xff\\x00\"6\\xbd\\xff\\x00`\\xf9\\xff\\x00\\xf4\\x03@\\x1e-\\xf0\\xda]:5\\xfb]\\xe0\\x89\\xe5\\xb2\\xb5\\x80\\xc4\\xd38DFe\\xc7S\\xd5\\xb6\\xf6\\xc1\\xeb]\\x1e\\xb3\\xe2\\xb9sq-\\x85\\xdc\\xb7\\x88\\xe4\\xaf\\xcd\\x84\\x8e\\x05 \\x8c*\\xf5f \\x9eO\\x03\\xafZ\\xf37\\xd1<A\\xa6\\xf8\\x7fH\\xb8Xb\\x9e;\\xc8\\xa3pw\\xed\\x11\\xab(\\xd8\\xa5\\xb8\\xf9\\x8f<\\x0e@Z\\xf4=4[\\x8d\\n\\xcd\\xe5\\x8e\\xd9|\\xb8\\x80\\x95a\\\\/\\x99\\xeb\\xcf_\\xc6\\xbc\\xea\\xd3\\x954\\x92\\xd1\\xdf\\xef=\\xba\\xdfW\\xafR5$\\xdc\\xadk\\xf4I%\\xb7\\x99b\\xcf\\xe2\\x84\\xb0\\x91\\x1e\\xa5\\xa4\\x90\\x81~Ym\\xa6\\x07\\'\\xdd\\x18\\x0c~f\\xa9\\xea_\\x18tK\\xa7\\x1ajG\\xa9\\xd9\\xc7rZ\\xdek\\xf6A\\x1f\\xd9K)\\xc3\\x0eNH\\xe0\\xfd9\\xaa\\xba\\xbe\\x9fd-\\x85\\xc4n\\xa9\\x19R\\xc4\\x1e6\\x8frzW\\x97\\xc3q\\x06\\xb1\\'\\x89,\\xa2\\x1edf\\xcc\\\\B\\xc0g\\xe7\\x80\\x83\\xb8{\\x15.?\\x1a\\xd7\\x0f^u\\x1b\\x8c\\x96\\xc76*\\x8d\\x08\\xd3\\x8c\\xe9=_C\\xe8\\xdd\\x06\\xde\\xcfE\\xd0\\xac\\xb4\\xdb[\\x8f>\\x18bP\\'\\xce\\xef0\\xb1?1#\\x8c\\x93\\x93\\xf8\\xd6\\x9bK\\xdc\\x9f\\xce\\xbeh\\xf8y\\xe3\\xe9|-#\\xd8\\xbc&kk\\x99\\xe3s\\x87\\xc1\\x18\\x04\\x103\\xc79\\x1fB+\\xdaO\\x89\\x96\\xf2\\xd3NT\\xb5\\x9eG\\xd6Z[[h\\x95\\x80\\xdb,e\\x84\\x80\\xb7a\\xc5i8K\\xa1\\xcb\\t\\xc6\\xda\\x9d\\x1d\\xfd\\xccp\\xd8K4\\xb7\\x0b\\x04*\\xbb\\x9ef8\\x08\\xbd\\xce\\x7f\\x97\\xe1Xw\\x9e+\\x0bg7\\xf6L_\\xda\\xd7P\\xda=\\xcc\\x82&\\x0b\\xb1T\\x85%\\x97\\xaerrTs\\x80}\\xab\\xcf.u\\x0b\\xef\\x10_xgR\\xba@m&\\x8a[y\\x90)\\x0bis\\x14\\x9b\\x88p:}\\xd4\\xf7*q\\xd7\\xaf\\xa7\\x7f\\xc2Q\\xa1\\xb6\\xbfiy`\\x02j\\x93@b\\x92\\xd9\\xc6\\xc7\\x99\\xe4\\xdb\\xb5\\x08\\xc6I\\x1e^w\\x0e098\"\\xa3\\xd8\\xa5\\xac\\x98\\xfd\\xab\\x7f\\n\\x19w\\xe1\\x8dj\\xec\\xc1\\xa7\\xcb}k.\\x93\\xa8\\xb1i\\xee\\xad\\xad\\xf0\\xe8J\\xee\\x0b\\xb1\\xcb.\\xc6 r?,\\x9c\\xd4\\xf66\\xb3i\\x93\\xddi\\xf72E,\\xb08\\xdb*.\\x19\\xe2#+\\xbb\\xbe~\\xf0\\xe4\\x9e\\x9dOZ\\xa3t\\x9e/\\xbeH\\xa1\\xd3\\x9fR\\xb7\\x81]\\x91\\x16\\xdd`\\xb6X\\x9a>1\\xf3\\x06f\\\\\\xe4\\x00x\\'\\xbe*{\\x14\\x97\\xcc\\x92\\xea\\xe6{\\xd9\\xeegU\\xcc\\x97\\x88\\xa8\\xfb\\x01m\\xa0\\x05\\x00\\x00\\tn\\xd9\\xfd+\\x1c_$ih\\xack\\x87\\xe6u5c\\xac\\x8e~(\\xe8\\xdf\\xf6\\x0c\\xbc\\xff\\x00\\xd0\\xe1\\xafG\\xaf5\\xd3\\xce~(\\xe8\\xdf\\xf6\\x0c\\xbc\\xff\\x00\\xd0\\xe1\\xafJ\\xad\\xf0n\\xf4#\\xfdu0\\xc4\\xabU\\x90QE\\x15\\xd4`\\x14QE\\x00\\x14QE\\x00\\x14QE\\x00\\x14QE\\x00\\x15\\x85\\xe3_\\xf9\\x11u\\xef\\xfb\\x07\\xcf\\xff\\x00\\xa0\\x1a\\xdd\\xac/\\x1a\\xff\\x00\\xc8\\x8b\\xaf\\xff\\x00\\xd8>\\x7f\\xfd\\x00\\xd0\\x07\\x99\\xe8\\x1ag\\xdb\\xbc\\x07g\\x9b\\xbb\\x9b\\x89!\\xb1\\x8eX\\xe3b\\x08S\\xe5\\x8f\\x94\\x0fLp+#C\\xd4\\x05\\xc0\\x0c\\x9b\\x162pA^\\x18\\x0e\\xb9\\x15\\xda\\xf8I \\xb6\\xf0\\x86\\x90\\xdb\\xf7Jt\\xeb\\x7f\\xbc>\\xe81\\xa9?\\x85f\\x8f\\x0ci\\x900\\xf2s\\x0c~s\\xcacN\\x9f7;G\\xa0\\xceO\\xe3\\\\\\xf8\\xbc\\x1cf\\x94\\xe3\\xa3=,-H\\xd3\\x93\\x8c\\xbe\\x07\\xd3\\xcc\\xe7|E\\xaa[\\xdbiw\\x13\\x98\\x17\\xc8\\x85q${w\\x0ez/<`\\xd7\\x92x6{\\x8bMo\\xed\\xd0\\xdb=\\xcd\\xba#\\xa5\\xdd\\xbc\\\\\\xb9\\x81\\xc1W!z\\x90\\x01\\xed\\xd3\\x02\\xbd\\xb7\\xc6\\x1a5\\xb6\\xa5`\\x04q\"\\x07O\\xb2\\xc9\\x91\\xc6\\xd6\\xfb\\x8c}\\xd5\\xf6\\x9c\\xfa\\x16\\xf5\\xaf-\\xf0\\x8f\\x86\\'K\\xebV\\xbb\\x92\\xe3N\\x9a\\xe8o\\xd3\\xb5\\x18y\\x11\\xcc\\xa4\\x83\\x1bv\\xe7\\x04`\\xfa{\\xd4\\xd0\\xa4\\xa8\\xc5\\xa6\\xefs\\x1cMOi5\\xca\\xac\\x91\\xcc^\\xe9o\\xa2\\xea\\xd1\\x92\\xf1Mj\\xcd\\xbe\\xde\\xe5\\xb2b\\x95;\\x1e9\\xfa\\x8e\\xa0\\xf0k\\xbc\\xd1\\xf5}^\\xe6\\xd3O\\xd3l\\xfcK\\xe1\\xbbC\\xa5\\xc9-\\xfcWR\\xb4\\x83cH\\xd8o\\x99\\x93\\x03\\x1b\\xce\\x14\\x0e\\xfd\\xfbw7\\xad}\\xfd\\x9a\\xd6w\\x0b\\xe1\\xe9\\xaf\\xc1\\xde\\xf1O\\x81\\x1d\\xc8\\xf5\\xdayF\\xf7\\xe4W\\x9c\\xea\\x9a\\xfe\\x9d\\xa5\\xdc\\x18\\xb5O\\x87:|R\\x9e\\x8c$`\\xad\\xee\\x08\\x18?\\x85k\\x1a\\x8d\\xec\\x8ceJ\\xddN\\xff\\x00\\xc2\\xa9\\xe1\\x9f\\x0e\\x1d\\xfa\\x97\\x8d_S\\x93T\\x8aK\\xc3\\x1c0\\x85\\x80\\x88\\xc9iz\\x8f\\xe2*\\xc0t\\xce\\x0f\\x1d+\\xa6\\x97\\xe2?\\x83\\xed.\\x17\\xfb:\\x08\\r\\xc4\\xfaI\\xbf\\xb7p\\x14\\xfc\\xc3; \\x00d\\x87\\'?(\\xaf\\x08\\x97\\xc6\\xfaF\\xd5\\x16\\xfe\\x0b\\xd2P\\xa8\\xc2\\xf9\\x8e\\xf2\\x01\\xf8\\x13U\\xff\\x00\\xe1=\\xd4\\x1d\\xc4qGm\\xa5\\xdb\\x1e\\x1f\\xfb.\\xd9\"\\x90\\x8ff<\\xfe\\xb4\\xf5\\xdd\"t\\xd9\\xb3\\xdbt\\xff\\x00\\x88\\x9e86\\x02}GH\\xd1-ey\\x84\\x89\\x15\\xc5\\xf7\\xd9\\xd8\\xc4G\\xdd\\xdarA\\xe8r\\x7f*\\xd2\\xb2\\xf1\\x05\\xfe\\xaf2\\xae\\xa9\\xf6U\\xba14\\x82;m\\xc4$~c(\\xcb\\x1e\\xbe\\x80\\x8e\\xa0f\\xbcB\\xd7\\xc5~\\x1f\\xb5\\x0b\\x1d\\x8f\\x87\\xe1\\x9e\\xe6C\\x99o\\xb5\\xa9|\\xe2O\\xa9\\x00\\x7f*\\xf4\\x7f\\x0cj\\x96:\\x96\\xa1\\x05\\xdd\\x9c\\xf6O\\'\\xd8\\x85\\xb5\\xcc\\x16\\x84\\xed\\x84\\xab\\x96B\\xa0\\x80v\\x9c\\xb0\\xe9\\xc7\\x15\\xc1\\x8c\\x95GM\\xa9-\\x0e\\xdc,i\\xf3\\xa6\\xb7:\\xcd(\\xe7\\xe2\\x8e\\x8f\\xff\\x00`\\xcb\\xcf\\xfd\\x0e*\\xf4\\xea\\xf2\\xed\\x19\\xb7|P\\xd20r?\\xb3.\\xff\\x00\\xf48\\xab\\xd4k\\xa3\\x01\\xfe\\xef\\x1f\\xeb\\xa9\\xcf\\x8b\\xfe4\\xbf\\xae\\x81E\\x14WY\\xcc\\x14QE\\x00\\x14QE\\x00\\x14QE\\x00\\x14QE\\x00\\x15\\x85\\xe3_\\xf9\\x11u\\xff\\x00\\xfb\\x07\\xcf\\xff\\x00\\xa0\\x1a\\xdd\\xac/\\x1a\\xff\\x00\\xc8\\x8b\\xaf\\xff\\x00\\xd8>\\x7f\\xfd\\x00\\xd0\\x07\\x0f\\xe1\\x9b\\x92\\xde\\r\\xd1\\x10\\xf2V\\xc2\\x01\\x93\\xe9\\xb0V\\x81e\\xef\\xb6\\xb0\\xfc2\\xc0\\xf8SG\\xc1\\xff\\x00\\x97\\x18{\\xff\\x00\\xb0+I\\xe3V\\xf653\\x9bz\\x1d\\x91Z\\r\\xbf\\x9a\\xda;\\x1b\\x89.\\n\\x88Q\\x0b\\xb9\\x038\\x0b\\xce\\x7fJ\\xe4\\x12\\xd3ZM~+]:\\xe2\\x0f\\xecAj\\xb2\\xc8.!\\xf3\\x12FyY\\x8e\\xdc\\x7f\\x16\\x08\\xe7>\\x95\\xd3\\xc8\\xa0nF\\xc3\\x020A\\xe4\\x11X\\xdf\\xf0\\x8di^_\\x93\\xe5\\xdc\\x0b\\x7f\\xf9\\xf6\\x172\\x08\\xbe\\x9b7c\\x1e\\xdd+\\x96SKsNF\\xf62\\xbcI\\xae\\xf8?R\\xf3lu(\\xe1\\xbb\\xb9\\x87\\x81\\x1b0\\x8d\\xff\\x00\\xe0\\x12\\x13\\x8c\\xfbdW\\x8ek\\xd0ZA~V\\xc6\\xd2\\xfa\\xd6\\x03\\xc8K\\xb6\\x0c~\\xa0\\x80\\x06??\\xad}\\x0b\\x1e\\x9b\\xa7E\\x07\\x90\\x9a}\\xa2\\xc3\\x8cl\\x10.1\\xf4\\xc5f\\xdc\\xf8CG\\x9dYa\\x85\\xedCuX\\x1b\\t\\xff\\x00|\\x1c\\xaf\\xe9Q\\x0cD!\\xa6\\xa3\\xa9\\x87\\x9c\\xfb\\x1f<)\\n\\xc0\\x91\\x91\\x9eG\\xadI;G,\\xcc\\xd0\\xc5\\xe5\\xa1\\xe8\\x9b\\xb7c\\xf15\\xeb\\xb7\\xbf\\x0c\\x12V-owh\\xc3\\xb2\\xcdi\\xb3\\xf5\\x8d\\x87\\xf2\\xaa\\xf6\\xff\\x00\\x0e/\\xed\\xa4\\x05a\\xd0Xz\\xc9\\x1c\\xcf\\xfa\\x16\\xc5k\\xf5\\xca6\\xbd\\xce\\x7f\\xaaU\\xbd\\xacy\\xde\\x89\\xe1\\xfb\\xddrr\\xb0(\\x8e\\xde>g\\xba\\x90\\xed\\x8e\\x15\\xeeY\\xbf\\xa7Z\\xee\\xfc\\x1d\\x06\\x8d\\xe1\\x8dz\\xefS\\x97Z\\x81\\xe3Thm\\xed\\xe1-$\\xb2\\x82G$\\x01\\xd4\\xe38\\xf7\\xf6\\xae\\xbe\\xdb\\xc2rJ!McP\\x17V\\xd0\\xb0t\\xb2\\xb7\\x81`\\xb7\\x0c:\\x12\\xa3\\x96\\xfck\\xa8\\xdc3\\x9c\\x0c\\xf4\\xcdy\\xb8\\xac\\xc6-8-S\\xed\\xff\\x00\\x0cw\\xe1\\xf0-5\\'\\xba2\\xfe\\x1e\\xcdsq\\xe3=\\x12[\\xbbim\\xe4k\\x0b\\xf6X\\xe5?>\\xc34eK{\\xe0\\xd7\\xb5\\xd7\\x94x|\\xe7\\xe2\\x86\\x95\\xff\\x00`\\xcb\\xbf\\xfd\\x0e*\\xf5z\\xf4p3\\xe7\\xa1\\x19Z\\xd7\\xbf\\xe6\\xce\\x0c\\\\yk5\\xe9\\xf9\\x05\\x14Q]g0QE\\x14\\x00QE\\x14\\x00QE\\x14\\x00QE\\x14\\x00V\\x17\\x8dy\\xf06\\xbc\\x07\\xfd\\x03\\xe7\\xff\\x00\\xd0\\rn\\xd4s\\xc4\\x93\\xc1$2(h\\xddJ\\xb2\\x9e\\xe0\\xf0E\\x00x\\xc7\\x87P?\\x85t\\x86C\\x83\\xf6(y\\x1d\\xfeAW\\x84\\xf2/\\x1b\\x8ek\\x9f\\xc4\\xbf\\x0e\\xf5w\\xf0\\xee\\xb0\\x1d4\\xa6\\x90\\x9d3Qq\\xfb\\xb6Bs\\xe5\\xb3t\\x0c9\\xff\\x00\\xf5b\\xb4f\\xd5\\xf4\\xc2\\xe1\\x92\\xfe\\xd4\\xe4s\\x89\\x97\\xf3\\xeb\\\\\\xf3\\xba;\\xe98\\xb8\\x97\\xbc\\xc2\\xc4\\x92ri7f\\xa8.\\xad\\xa7\\x81\\xcd\\xf5\\xa9>\\xber\\xff\\x00\\x8d \\xd5l?\\xe7\\xfa\\xd7\\xfe\\xff\\x00/\\xf8\\xd7-K\\x9d\\x10\\xb1\\xa3\\xba\\x94\\x1a\\xcf\\x1a\\xad\\x87\\xfc\\xff\\x00Z\\xff\\x00\\xdf\\xe5\\xff\\x00\\x1ap\\xd5l?\\xe7\\xfe\\xd7\\xfe\\xff\\x00/\\xf8\\xd7\\x1c\\xe2\\xfb\\x1b\\xc5\\xae\\xe5\\xec\\xd2\\xe6\\xa8\\xff\\x00ji\\xff\\x00\\xf3\\xff\\x00k\\xff\\x00\\x7f\\x97\\xfci\\xc3T\\xd3\\xff\\x00\\xe7\\xfe\\xd7\\xfe\\xff\\x00\\xaf\\xf8\\xd7$\\xe3.\\xc6\\xf1\\x92\\xee]\\xcd\\x19\\xaa\\x7f\\xda\\x9a\\x7f\\xfc\\xff\\x00\\xda\\xff\\x00\\xdf\\xf5\\xff\\x00\\x1a\\xa9\\xa8x\\x97H\\xd3m\\xcc\\xb3_B\\xecxH\\xa1p\\xef!\\xec\\x15GS\\\\\\x92\\xa59;$\\xcd\\x95HE]\\xb3c\\xc3\\x8c\\x0f\\xc5\\x1d,ddi\\x97G\\x1f\\xf08\\xab\\xd6\\xab\\xcd\\xfe\\x1bxcQ\\x8e\\xf2\\xe7\\xc5z\\xf4?g\\xbf\\xbc\\x88Ckhz\\xdbA\\x9c\\xe1\\xbf\\xdac\\x82k\\xd2+\\xea\\xf0teF\\x84i\\xcbt|\\xde*\\xa2\\xabZS\\x8e\\xc1E\\x14WI\\x80QE\\x14\\x00QE\\x14\\x00QE\\x14\\x00QE\\x14\\x00QE\\x14\\x01^\\xf6\\xc6\\xd3P\\xb6k{\\xdbhn`o\\xbd\\x14\\xc8\\x1dO\\xe0k\\'\\xfe\\x10\\xbf\\n\\xff\\x00\\xd0\\xb7\\xa4\\x7f\\xe0\\x14\\x7f\\xe1E\\x14\\x00\\x7f\\xc2\\x15\\xe1_\\xfa\\x16\\xf4\\x8f\\xfc\\x02\\x8f\\xfc)?\\xe1\\n\\xf0\\xaf\\xfd\\x0bZG\\xfe\\x01G\\xfe\\x14Q@\\x0b\\xff\\x00\\x08W\\x85\\x7f\\xe8[\\xd2?\\xf0\\n?\\xf0\\xa3\\xfe\\x10\\xaf\\n\\xff\\x00\\xd0\\xb7\\xa4\\x7f\\xe0\\x14\\x7f\\xe1E\\x14\\x00\\x7f\\xc2\\x15\\xe1_\\xfa\\x16\\xf4\\x8f\\xfc\\x02\\x8f\\xfc(\\xff\\x00\\x84+\\xc2\\xbf\\xf4-\\xe9\\x1f\\xf8\\x05\\x1f\\xf8QE\\x00\\x1f\\xf0\\x85xW\\xfe\\x85\\xbd#\\xff\\x00\\x00\\xa3\\xff\\x00\\n\\x9a\\xd3\\xc2\\xde\\x1e\\xb0\\xb9K\\x8b=\\x0fM\\xb7\\x9d\\x0eVH\\xadQY~\\x84\\n(\\xa0\\r\\x8e\\x94QE\\x00\\x14QE\\x00\\x14QE\\x00\\x14QE\\x00\\x7f\\xff\\xd9'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category ID tf.Tensor(1000010653, shape=(), dtype=int64) \n",
            "Product ID- tf.Tensor(0, shape=(), dtype=int64) \n",
            "Height- tf.Tensor(180, shape=(), dtype=int64) \n",
            "Weidth- tf.Tensor(180, shape=(), dtype=int64) \n",
            "depth- tf.Tensor(3, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing-2"
      ],
      "metadata": {
        "id": "5i45vPTjR0Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading Tfrecord file\n",
        "import IPython.display as display\n",
        "\n",
        "data_dir = \"../cdiscount/\"\n",
        "\n",
        "train_tfrecord_path = os.path.join(data_dir, \"train_TFrecords.tfrecords\")\n",
        "\n",
        "\n",
        "raw_dataset = tf.data.TFRecordDataset(train_tfrecord_path,num_parallel_reads=tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "DATASET_SIZE=1232287\n",
        "\n",
        "\n",
        "################################################Train/Validation Split############################\n",
        "train_size = int(0.7 * DATASET_SIZE)\n",
        "val_size = int(0.15 * DATASET_SIZE)\n",
        "test_size = int(0.15 * DATASET_SIZE)\n",
        "\n",
        "full_dataset = tf.data.TFRecordDataset(train_tfrecord_path)\n",
        "print(\"Full_dataset-\",full_dataset)\n",
        "# full_dataset = full_dataset.shuffle(buffer_size=1000)\n",
        "train_dataset = full_dataset.take(train_size)\n",
        "print('TFREC-',train_dataset)\n",
        "test_dataset = full_dataset.skip(train_size)\n",
        "# val_dataset = test_dataset.skip(val_size)\n",
        "# test_dataset = test_dataset.take(test_size)\n",
        "\n",
        "#################################\n",
        "\n",
        "#############################################################################################\n",
        "\n",
        "from PIL import Image\n",
        "def parse_tfr_element(element,img_shape=180):\n",
        "  #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
        "  data = {\n",
        "      'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "      'width':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'depth':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'category_id':tf.io.FixedLenFeature([], tf.int64),      \n",
        "      'product_id':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'img_raw' : tf.io.FixedLenFeature([], tf.string)\n",
        "          }    \n",
        "  \n",
        "  content = tf.io.parse_single_example(element, data) \n",
        "  \n",
        "  height = content['height']\n",
        "  width = content['width']\n",
        "  depth = content['depth']\n",
        "  label = content['category_id']\n",
        "  product_id = content['product_id']\n",
        "  img_raw = content['img_raw']\n",
        "      \n",
        "  \n",
        "  #get our 'feature'-- our image -- and reshape it appropriately\n",
        "  # image = tf.io.parse_tensor(img_raw,out_type=tf.uint8)\n",
        "  image =tf.io.decode_raw(img_raw,tf.uint8,fixed_length=97200)\n",
        "  image = tf.reshape(image, [180, 180, 3])\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  return (image, label)\n",
        "\n",
        "\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "\n",
        "def get_dataset_small(filename):\n",
        "  #create the dataset\n",
        "  dataset = tf.data.TFRecordDataset(filename)\n",
        "\n",
        "  #pass every single feature through our mapping function\n",
        "  dataset = dataset.map(parse_tfr_element,num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "  return dataset\n",
        "\n",
        "################################################################################################\n",
        "\n",
        "train_tfrecord_path = os.path.join(data_dir, \"train_TFrecords.tfrecords\")\n",
        "Total_dataset = get_dataset_small(train_tfrecord_path)\n",
        "# train_data = get_dataset_small(train_dataset)\n",
        "\n",
        "\n",
        "#Splitting the data \n",
        "\n",
        "#Total Images in train bson= 12371293\n",
        "\n",
        "Total_Images=12371293\n",
        "train_split = 0.6\n",
        "validation_split = 0.2\n",
        "\n",
        "num_train_images = int(Total_Images * train_split)\n",
        "num_validation_images = int(Total_Images * validation_split)\n",
        "\n",
        "train_dataset = Total_dataset.take(num_train_images)\n",
        "validation_dataset = Total_dataset.skip(num_train_images).take(num_validation_images)\n",
        "test_dataset = Total_dataset.skip(num_train_images + num_validation_images)\n",
        "\n",
        "\n",
        "train_dataset=train_dataset.shuffle(buffer_size=1000).batch(batch_size=128).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "validation_dataset=validation_dataset.shuffle(buffer_size=1000).batch(batch_size=128).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "for image, label in validation_dataset.take(1):\n",
        "  print(image[0].shape)\n",
        "  print(image[1].shape)\n",
        "  print(image)\n",
        "  print(label)\n",
        "  # print(sample[0][1])\n",
        "  # print(sample[1][0])\n",
        "\n",
        "\n",
        "\n",
        "# for sample in Total_dataset.take(1):\n",
        "#   print(sample[0].shape)\n",
        "#   print(sample[1].shape)\n",
        "#   print(sample[0][1])\n",
        "#   print(sample[1][0])\n",
        "\n",
        "\n",
        "########################################################################################\n",
        "\n",
        "\n",
        "\n",
        "################################################################################################\n",
        "\n",
        "# train_tfrecord_path = os.path.join(data_dir, \"train_TFrecords.tfrecords\")\n",
        "# train_data = get_dataset_small(train_tfrecord_path)\n",
        "# print(\"Data before shuffle and batching- \", train_data)\n",
        "\n",
        "# print(\"\\nData before shuffle and batching-USING TAKE- \", train_data.take(1))\n",
        "\n",
        "# # train_data=train_data.shuffle(buffer_size=1000).batch(batch_size=128).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "# # print(\"\\nData AFTER shuffle and batching- \", train_data)\n",
        "\n",
        "# for image, label in train_data.take(1):\n",
        "#   print(image[0].shape)\n",
        "#   print(image[1].shape)\n",
        "#   print(image)\n",
        "#   print(label)\n",
        "#   # print(sample[0][1])\n",
        "#   # print(sample[1][0])\n",
        "\n",
        "\n",
        "########################################################################################\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpXcZw6_Ryug",
        "outputId": "1b028225-1525-4578-9159-13e3caaaa10a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full_dataset- <TFRecordDatasetV2 shapes: (), types: tf.string>\n",
            "TFREC- <TakeDataset shapes: (), types: tf.string>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "EAdA94pFxHvG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a dataset out of the parse elements, we simply leverage the tf.data API. We create a TFRecordDataset by pointing it to the TFRecord file on our disk and then apply our previous parsing function to every extracted Example. This returns a dataset:"
      ],
      "metadata": {
        "id": "I-WbwXSRi9OX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create modelling callbacks\n"
      ],
      "metadata": {
        "id": "cTSApKeXhxuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get helper_functions.py script from course GitHub\n",
        "!wget https://raw.githubusercontent.com/sarthakkaushik/Cdiscount-Image-Classification/main/helper.py\n",
        "\n",
        "# Import helper functions we're going to use\n",
        "from helper import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir\n",
        "\n",
        "dir_name = '/gdrive/MyDrive/UOH Assignment Dataset/cdiscount/Tensorboard'\n",
        "def create_tensorboard_callback(experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "\n",
        "# Setup checkpoint path\n",
        "checkpoint_path = '/gdrive/MyDrive/UOH Assignment Dataset/cdiscount/CheckPoints/EfficientNet/Efficient_Tfrecord_test.ckpt' # note: remember saving directly to Colab is temporary\n",
        "\n",
        "# Create a ModelCheckpoint callback that saves the model's weights only\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                         save_weights_only=True, # set to False to save the entire model\n",
        "                                                         save_best_only=False, # set to True to save only the best model instead of a model every epoch \n",
        "                                                         save_freq=\"epoch\", # save every epoch\n",
        "                                                         verbose=1)"
      ],
      "metadata": {
        "id": "iB__IfLIh4zz",
        "outputId": "75dddb23-dfd2-4160-f897-2e26ddfa1836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-15 05:22:17--  https://raw.githubusercontent.com/sarthakkaushik/Cdiscount-Image-Classification/main/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10510 (10K) [text/plain]\n",
            "Saving to: helper.py.10\n",
            "\n",
            "\rhelper.py.10          0%[                    ]       0  --.-KB/s               \rhelper.py.10        100%[===================>]  10.26K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2022-01-15 05:22:18 (4.43 MB/s) - helper.py.10 saved [10510/10510]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn on mixed precision training\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(policy=\"mixed_float16\") # set global policy to mixed precision \n",
        "\n",
        "mixed_precision.global_policy() # should output \"mixed_float16\""
      ],
      "metadata": {
        "id": "VOMKHjvjh42m",
        "outputId": "754fbf2e-0c32-4dc1-e959-0312f5e72d78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
            "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
            "  Tesla P100-PCIE-16GB, compute capability 6.0\n",
            "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
            "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Policy \"mixed_float16\">"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Build feature extraction model"
      ],
      "metadata": {
        "id": "G7di2EACi-Vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "\n",
        "num_classes = 5270\n",
        "# Create base model\n",
        "input_shape = (180, 180, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB7(include_top=False)\n",
        "base_model.trainable = False # freeze base model layers\n",
        "\n",
        "# Create Functional model \n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\", dtype=tf.float16)\n",
        "# Note: EfficientNetBX models have rescaling built-in but if your model didn't you could have a layer like below\n",
        "# x = preprocessing.Rescaling(1./255)(x)\n",
        "x = base_model(inputs, training=False) # set base_model to inference mode only\n",
        "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
        "x = layers.Dense(num_classes)(x) # want one output neuron per class \n",
        "# Separate activation of output layer so we can output float32 activations\n",
        "outputs = layers.Activation(\"softmax\", dtype=tf.float32, name=\"softmax_float32\")(x) \n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", # Use sparse_categorical_crossentropy when labels are *not* one-hot\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "zAhkbyqih45L",
        "outputId": "e2dbd4e2-e42e-447e-82e7-ca53df157f3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "258080768/258076736 [==============================] - 2s 0us/step\n",
            "258088960/258076736 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ZaMbOn3qh47v",
        "outputId": "f2ae2acd-6b48-43ed-9502-0a955eb9b2cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (InputLayer)    [(None, 180, 180, 3)]     0         \n",
            "                                                                 \n",
            " efficientnetb7 (Functional)  (None, None, None, 2560)  64097687 \n",
            "                                                                 \n",
            " pooling_layer (GlobalAverag  (None, 2560)             0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5270)              13496470  \n",
            "                                                                 \n",
            " softmax_float32 (Activation  (None, 5270)             0         \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77,594,157\n",
            "Trainable params: 13,496,470\n",
            "Non-trainable params: 64,097,687\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking layer dtype policies (are we using mixed precision?)\n",
        "\n",
        "# Check the dtype_policy attributes of layers in our model\n",
        "for layer in model.layers:\n",
        "  print(layer.name, layer.trainable, layer.dtype, layer.dtype_policy) # Check the dtype policy of layers"
      ],
      "metadata": {
        "id": "QqOCiccXh4-J",
        "outputId": "26692282-56df-4f73-b483-8170d6fd039f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer True float16 <Policy \"float16\">\n",
            "efficientnetb7 False float32 <Policy \"mixed_float16\">\n",
            "pooling_layer True float32 <Policy \"mixed_float16\">\n",
            "dense True float32 <Policy \"mixed_float16\">\n",
            "softmax_float32 True float32 <Policy \"float32\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model with callbacks\n",
        "tf_history_1 = model.fit(train_dataset, \n",
        "                         epochs=3,\n",
        "                         validation_data=validation_dataset,\n",
        "                         callbacks=[checkpoint_callback,create_tensorboard_callback(\"efficientnetb7_Tfrecord_feature_extract\")])"
      ],
      "metadata": {
        "id": "N0KOrv3th5AV",
        "outputId": "a36a1b8b-baa9-4dfe-f061-0cc94349cf0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: /gdrive/MyDrive/UOH Assignment Dataset/cdiscount/Tensorboard/efficientnetb7_Tfrecord_feature_extract/20220115-052435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "    448/Unknown - 210s 393ms/step - loss: nan - accuracy: 0.0000e+00"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Cl26YaIah5Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_one_sample=dataset.take(1)\n",
        "# Output info about our training sample\n",
        "for image, label in train_one_sample:\n",
        "  print(f\"\"\"\n",
        "  Image shape: {image.shape}\n",
        "  Image dtype: {image.dtype}\n",
        "  Target class from Food101 (tensor form): {label}\n",
        "  \n",
        "        \"\"\")\n",
        "  # print(image)\n",
        "  print(tf.reduce_min(image), tf.reduce_max(image))\n",
        "  print(tf.squeeze())\n",
        "  plt.imshow(image)\n",
        "  # plt.title(class_names[label.numpy()]) # add title to image by indexing on class_names list\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "XW6x0b7VibiI",
        "outputId": "9b8cf192-8e7e-4743-d3cb-e7dff226f01d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Image shape: (128, 180, 180, 3)\n",
            "  Image dtype: <dtype: 'float32'>\n",
            "  Target class from Food101 (tensor form): [1000003983 1000010653 1000010653 1000007590 1000010653 1000004085\n",
            " 1000010653 1000010653 1000010667 1000010653 1000010653 1000010653\n",
            " 1000010653 1000008933 1000016258 1000018705 1000010667 1000010722\n",
            " 1000009591 1000010667 1000010653 1000004085 1000010635 1000010653\n",
            " 1000008094 1000010667 1000010653 1000010667 1000010635 1000011423\n",
            " 1000010661 1000004079 1000010653 1000010667 1000010653 1000010108\n",
            " 1000010653 1000010661 1000010661 1000004079 1000014217 1000010793\n",
            " 1000021533 1000010653 1000010136 1000004085 1000010108 1000002852\n",
            " 1000010667 1000010667 1000010653 1000004079 1000010538 1000005956\n",
            " 1000010653 1000010645 1000011566 1000010645 1000011566 1000010667\n",
            " 1000010653 1000003796 1000010653 1000010667 1000010653 1000021535\n",
            " 1000004184 1000010683 1000010653 1000005956 1000010653 1000005956\n",
            " 1000010100 1000021535 1000010653 1000016093 1000016980 1000010667\n",
            " 1000010653 1000010645 1000010667 1000010667 1000005760 1000005796\n",
            " 1000005796 1000018294 1000010653 1000010653 1000005326 1000010667\n",
            " 1000008535 1000010667 1000005910 1000010653 1000005732 1000010136\n",
            " 1000012993 1000010653 1000014287 1000010053 1000010661 1000004079\n",
            " 1000010653 1000010653 1000005796 1000010653 1000010667 1000015309\n",
            " 1000010647 1000010667 1000004141 1000010667 1000010653 1000010053\n",
            " 1000010667 1000004079 1000002615 1000010653 1000010653 1000010667\n",
            " 1000010647 1000010653 1000014219 1000015309 1000021533 1000012989\n",
            " 1000010653 1000018284]\n",
            "  \n",
            "        \n",
            "tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(255.0, shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-7247ef7d8090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# print(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0;31m# plt.title(class_names[label.numpy()]) # add title to image by indexing on class_names list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (128, 180, 180, 3) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMbElEQVR4nO3bcYikd33H8ffHXFNpGrWYFeTuNJFeGq+2kHRJU4SaYlouKdz9YZE7CG1KyKE1UlAKKZZU4l9WakG41l6pRAWNp3+UBU8CtZGAeDEbEmPuQmQ9bXNRmjOm/iMaQ7/9YybtZL+7mSd3szO39f2ChXme+e3Md4fhfc8881yqCkma9IpFDyDpwmMYJDWGQVJjGCQ1hkFSYxgkNVPDkOQTSZ5O8tgm9yfJx5KsJXk0yTWzH1PSPA05Yrgb2PcS998I7Bn/HAb+4fzHkrRIU8NQVfcDP3yJJQeAT9XICeA1SV4/qwElzd+OGTzGTuDJie0z433fX78wyWFGRxVccsklv3XVVVfN4Oklbeahhx76QVUtvdzfm0UYBquqo8BRgOXl5VpdXZ3n00s/d5L8+7n83iy+lXgK2D2xvWu8T9I2NYswrAB/PP524jrgR1XVPkZI2j6mfpRI8lngeuCyJGeAvwZ+AaCqPg4cB24C1oAfA3+6VcNKmo+pYaiqQ1PuL+A9M5tI0sJ55aOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6RmUBiS7EvyRJK1JHdscP8bktyX5OEkjya5afajSpqXqWFIchFwBLgR2AscSrJ33bK/Ao5V1dXAQeDvZz2opPkZcsRwLbBWVaer6jngHuDAujUFvGp8+9XA92Y3oqR5GxKGncCTE9tnxvsmfRC4OckZ4Djw3o0eKMnhJKtJVs+ePXsO40qah1mdfDwE3F1Vu4CbgE8naY9dVUerarmqlpeWlmb01JJmbUgYngJ2T2zvGu+bdCtwDKCqvga8ErhsFgNKmr8hYXgQ2JPkiiQXMzq5uLJuzX8AbwdI8mZGYfCzgrRNTQ1DVT0P3A7cCzzO6NuHk0nuSrJ/vOz9wG1JvgF8Frilqmqrhpa0tXYMWVRVxxmdVJzcd+fE7VPAW2c7mqRF8cpHSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUDApDkn1JnkiyluSOTda8M8mpJCeTfGa2Y0qapx3TFiS5CDgC/D5wBngwyUpVnZpYswf4S+CtVfVsktdt1cCStt6QI4ZrgbWqOl1VzwH3AAfWrbkNOFJVzwJU1dOzHVPSPA0Jw07gyYntM+N9k64Erkzy1SQnkuzb6IGSHE6ymmT17Nmz5zaxpC03q5OPO4A9wPXAIeCfkrxm/aKqOlpVy1W1vLS0NKOnljRrQ8LwFLB7YnvXeN+kM8BKVf2sqr4DfItRKCRtQ0PC8CCwJ8kVSS4GDgIr69b8C6OjBZJcxuijxekZzilpjqaGoaqeB24H7gUeB45V1ckkdyXZP152L/BMklPAfcBfVNUzWzW0pK2VqlrIEy8vL9fq6upCnlv6eZHkoapafrm/55WPkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySmkFhSLIvyRNJ1pLc8RLr3pGkkizPbkRJ8zY1DEkuAo4ANwJ7gUNJ9m6w7lLgz4EHZj2kpPkacsRwLbBWVaer6jngHuDABus+BHwY+MkM55O0AEPCsBN4cmL7zHjf/0pyDbC7qr74Ug+U5HCS1SSrZ8+efdnDSpqP8z75mOQVwEeB909bW1VHq2q5qpaXlpbO96klbZEhYXgK2D2xvWu87wWXAm8BvpLku8B1wIonIKXta0gYHgT2JLkiycXAQWDlhTur6kdVdVlVXV5VlwMngP1VtbolE0vaclPDUFXPA7cD9wKPA8eq6mSSu5Ls3+oBJc3fjiGLquo4cHzdvjs3WXv9+Y8laZG88lFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWDwpBkX5InkqwluWOD+9+X5FSSR5N8OckbZz+qpHmZGoYkFwFHgBuBvcChJHvXLXsYWK6q3wS+APzNrAeVND9DjhiuBdaq6nRVPQfcAxyYXFBV91XVj8ebJ4Bdsx1T0jwNCcNO4MmJ7TPjfZu5FfjSRnckOZxkNcnq2bNnh08paa5mevIxyc3AMvCRje6vqqNVtVxVy0tLS7N8akkztGPAmqeA3RPbu8b7XiTJDcAHgLdV1U9nM56kRRhyxPAgsCfJFUkuBg4CK5MLklwN/COwv6qenv2YkuZpahiq6nngduBe4HHgWFWdTHJXkv3jZR8Bfhn4fJJHkqxs8nCStoEhHyWoquPA8XX77py4fcOM55K0QF75KKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqRkUhiT7kjyRZC3JHRvc/4tJPje+/4Ekl896UEnzMzUMSS4CjgA3AnuBQ0n2rlt2K/BsVf0q8HfAh2c9qKT5GXLEcC2wVlWnq+o54B7gwLo1B4BPjm9/AXh7ksxuTEnztGPAmp3AkxPbZ4Df3mxNVT2f5EfAa4EfTC5Kchg4PN78aZLHzmXoBbmMdX/PBWw7zQrba97tNCvAr53LLw0Jw8xU1VHgKECS1apanufzn4/tNO92mhW217zbaVYYzXsuvzfko8RTwO6J7V3jfRuuSbIDeDXwzLkMJGnxhoThQWBPkiuSXAwcBFbWrVkB/mR8+4+Af6uqmt2YkuZp6keJ8TmD24F7gYuAT1TVySR3AatVtQL8M/DpJGvADxnFY5qj5zH3ImynebfTrLC95t1Os8I5zhv/YZe0nlc+SmoMg6Rmy8OwnS6nHjDr+5KcSvJoki8neeMi5pyY5yXnnVj3jiSVZGFfsw2ZNck7x6/vySSfmfeM62aZ9l54Q5L7kjw8fj/ctIg5x7N8IsnTm10XlJGPjf+WR5NcM/VBq2rLfhidrPw28CbgYuAbwN51a/4M+Pj49kHgc1s503nO+nvAL41vv3tRsw6dd7zuUuB+4ASwfKHOCuwBHgZ+Zbz9ugv5tWV0Uu/d49t7ge8ucN7fBa4BHtvk/puALwEBrgMemPaYW33EsJ0up546a1XdV1U/Hm+eYHRNx6IMeW0BPsTo/678ZJ7DrTNk1tuAI1X1LEBVPT3nGScNmbeAV41vvxr43hzne/EgVfcz+jZwMweAT9XICeA1SV7/Uo+51WHY6HLqnZutqarngRcup563IbNOupVRhRdl6rzjQ8bdVfXFeQ62gSGv7ZXAlUm+muREkn1zm64bMu8HgZuTnAGOA++dz2jn5OW+t+d7SfT/F0luBpaBty16ls0keQXwUeCWBY8y1A5GHyeuZ3Qkdn+S36iq/1roVJs7BNxdVX+b5HcYXcfzlqr670UPNgtbfcSwnS6nHjIrSW4APgDsr6qfzmm2jUyb91LgLcBXknyX0WfLlQWdgBzy2p4BVqrqZ1X1HeBbjEKxCEPmvRU4BlBVXwNeyeg/WF2IBr23X2SLT4rsAE4DV/B/J3F+fd2a9/Dik4/HFnQCZ8isVzM6KbVnETO+3HnXrf8Kizv5OOS13Qd8cnz7MkaHvq+9gOf9EnDL+PabGZ1jyALfD5ez+cnHP+TFJx+/PvXx5jDwTYzq/23gA+N9dzH6FxdGpf08sAZ8HXjTAl/cabP+K/CfwCPjn5VFzTpk3nVrFxaGga9tGH30OQV8Ezh4Ib+2jL6J+Oo4Go8Af7DAWT8LfB/4GaMjr1uBdwHvmnhtj4z/lm8OeR94SbSkxisfJTWGQVJjGCQ1hkFSYxgkNYZBUmMYJDX/AwqkUdV2nfELAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can explore the content of our dataset by taking a single data point:\n"
      ],
      "metadata": {
        "id": "MPd60CCmjFoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import io\n",
        "import IPython.display as display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# image_data = ... # byte values of the image\n",
        "# image = Image.open(io.BytesIO(image_data))\n",
        "# image.show()\n",
        "\n",
        "\n",
        "for data in dataset(1):\n",
        "\n",
        "\n",
        "\n",
        "    print(type(data))\n",
        "    print(\"*\"*100)\n",
        "    print(data)\n",
        "    print(\"*\"*100)\n",
        "    print(len(data[0]))\n",
        "    print(\"*\"*100)\n",
        "    print(type(data[0]))\n",
        "    print(\"*\"*100)\n",
        "    image_raw=data[0][50].numpy()\n",
        "    # image_raw\n",
        "    plt.imshow(image_raw)\n",
        "    # display.display(display.Image(data=image_raw))\n",
        "    # arr_ = np.squeeze(data) # you can give axis attribute if you wanna squeeze in specific dimension\n",
        "    # image = Image.open(io.BytesIO(arr_))\n",
        "    # image.show()\n",
        "\n",
        "    # # plt.imshow(arr_.astype(np.uint8))\n",
        "    # # plt.show()\n",
        "    # print(\"*\"*100)\n",
        "\n",
        "    # print(\"Shape-\",data.shape)\n",
        "    # print(\"*\"*100)\n",
        "    # print(l)\n",
        "    # print(\"*\"*100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "SwuVgZOspdXM",
        "outputId": "48e87836-60e7-451f-ad33-c189ec7a1d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-18c2d630897d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'PrefetchDataset' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing packages\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D,BatchNormalization,Dense, GlobalAveragePooling2D\n",
        "\n",
        "num_classes = 5270"
      ],
      "metadata": {
        "id": "RFwbQXWrQSNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------TRAINING------------------------------------------------#\n",
        "\n",
        "\n",
        "# Get helper_functions.py script from course GitHub\n",
        "!wget https://raw.githubusercontent.com/sarthakkaushik/Cdiscount-Image-Classification/main/helper.py\n",
        "\n",
        "# Import helper functions we're going to use\n",
        "from helper import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir\n",
        "\n",
        "dir_name = '/gdrive/MyDrive/UOH Assignment Dataset/cdiscount/Tensorboard'\n",
        "def create_tensorboard_callback(experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "\n",
        "# Setup checkpoint path\n",
        "checkpoint_path = '/gdrive/MyDrive/UOH Assignment Dataset/cdiscount/CheckPoints/EfficientNet/Efficient_Tfrecord_test.ckpt' # note: remember saving directly to Colab is temporary\n",
        "\n",
        "# Create a ModelCheckpoint callback that saves the model's weights only\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                         save_weights_only=True, # set to False to save the entire model\n",
        "                                                         save_best_only=False, # set to True to save only the best model instead of a model every epoch \n",
        "                                                         save_freq=\"epoch\", # save every epoch\n",
        "                                                         verbose=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "num_classes = 5270\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# Create base model\n",
        "input_shape = (180, 180, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB7(include_top=False)\n",
        "base_model.trainable = False # freeze base model layers\n",
        "\n",
        "# Create Functional model \n",
        "inputs = layers.Input(shape=input_shape, name=\"input_layer\", dtype=tf.float16)\n",
        "# Note: EfficientNetBX models have rescaling built-in but if your model didn't you could have a layer like below\n",
        "# x = preprocessing.Rescaling(1./255)(x)\n",
        "x = base_model(inputs, training=False) # set base_model to inference mode only\n",
        "x = layers.GlobalAveragePooling2D(name=\"pooling_layer\")(x)\n",
        "x = layers.Dense(num_classes)(x) # want one output neuron per class \n",
        "# Separate activation of output layer so we can output float32 activations\n",
        "outputs = layers.Activation(\"softmax\", name=\"softmax_float32\")(x) \n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", # Use sparse_categorical_crossentropy when labels are *not* one-hot\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "LnOq2b1iQG-m",
        "outputId": "5a6d0de7-4f5f-4afb-852b-a878d784eea1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-13 19:12:41--  https://raw.githubusercontent.com/sarthakkaushik/Cdiscount-Image-Classification/main/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10510 (10K) [text/plain]\n",
            "Saving to: helper.py.7\n",
            "\n",
            "helper.py.7         100%[===================>]  10.26K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2022-01-13 19:12:42 (4.44 MB/s) - helper.py.7 saved [10510/10510]\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "258080768/258076736 [==============================] - 1s 0us/step\n",
            "258088960/258076736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model with callbacks\n",
        "history = model.fit(dataset, \n",
        "                    epochs=3,\n",
        "                    validation_split=0.3,\n",
        "                    # validation_steps=int(0.15 * len(dataset)),\n",
        "                    # callbacks=[checkpoint_callback,create_tensorboard_callback(\"TranferLearning_EfficientNetB7_Tfrecord_Test\")]\n",
        ")"
      ],
      "metadata": {
        "id": "3jEF7FZn1rro",
        "outputId": "a0ceb176-ba31-4776-f500-86c99b1665d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-ef955d2b7aaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit(dataset, \n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                     \u001b[0;31m# validation_steps=int(0.15 * len(dataset)),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0;31m# callbacks=[checkpoint_callback,create_tensorboard_callback(\"TranferLearning_EfficientNetB7_Tfrecord_Test\")]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[0;34m(arrays, validation_split)\u001b[0m\n\u001b[1;32m   1482\u001b[0m     raise ValueError(\n\u001b[1;32m   1483\u001b[0m         \u001b[0;34m\"`validation_split` is only supported for Tensors or NumPy \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m         \"arrays, found following types in the input: {}\".format(unsplitable))\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FROM THE AUTHOR"
      ],
      "metadata": {
        "id": "YzmTLllcmwAF"
      }
    }
  ]
}