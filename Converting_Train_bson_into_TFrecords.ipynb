{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Converting Train.bson into TFrecords.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjM82JktpcDorh4prgdkf5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthakkaushik/Cdiscount-Image-Classification/blob/main/Converting_Train_bson_into_TFrecords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDOlzpKYBUW7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to mount google drive in case you are loading the data from your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "id": "EIPat3MwBcUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "data_path = '/gdrive/MyDrive/UOH Assignment Dataset/cdiscount'\n",
        "os.chdir(data_path)\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "o6W-RMRfBgl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"../cdiscount/\"\n",
        "\n",
        "train_bson_path = os.path.join(data_dir, \"train.bson\")\n",
        "num_train_products = 7069896\n",
        "\n",
        "# train_bson_path = os.path.join(data_dir, \"train_example.bson\")\n",
        "# num_train_products = 82\n",
        "\n",
        "test_bson_path = os.path.join(data_dir, \"test.bson\")\n",
        "num_test_products = 1768182"
      ],
      "metadata": {
        "id": "vcyBP87uBkAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import io\n",
        "import bson \n",
        "import tensorflow as tf\n",
        "# from PIL import Image  # or, whatever image library you prefer\n",
        "from skimage.io import imread \n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "# from subprocess import check_output\n",
        "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "# helper functions\n",
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def serialize_array(array):\n",
        "  array = tf.io.serialize_tensor(array)\n",
        "  return array\n",
        "\n",
        "tfrecords_filename = 'output_file.tfrecords'\n",
        "opts = tf.io.TFRecordOptions(compression_type = 'ZLIB')\n",
        "\n",
        "\n",
        "\n",
        "# on my workstation it takes about 5 min per 100k entries, so should finish in about 6h\n",
        "z = 0 \n",
        "data = bson.decode_file_iter(open(train_bson_path, 'rb'))\n",
        "with tf.io.TFRecordWriter(tfrecords_filename, options=opts) as writer:\n",
        "    for c, d in enumerate(data):       \n",
        "        n_img = len(d['imgs'])\n",
        "        for index in range(n_img):\n",
        "            img_raw = d['imgs'][index]['picture']\n",
        "            img = imread(io.BytesIO(img_raw))\n",
        "            height = img.shape[0]\n",
        "            width = img.shape[1]\n",
        "            product_id = d['_id']\n",
        "            category_id = d['category_id'] \n",
        "            example = tf.train.Example(features=tf.train.Features(feature={\n",
        "                'height': _int64_feature(height),\n",
        "                'width': _int64_feature(width),\n",
        "                'category_id': _int64_feature(category_id),\n",
        "                'product_id': _int64_feature(product_id),\n",
        "                'img_raw':_bytes_feature(img_raw)\n",
        "            }))\n",
        "            writer.write(example.SerializeToString())\n",
        "        z = z + 1\n",
        "        print(z)"
      ],
      "metadata": {
        "id": "CGzFFnDrBU8F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}