{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Converting Train.bson into TFrecords.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPSHfqxaPjEx7xd6icVti9h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthakkaushik/Cdiscount-Image-Classification/blob/main/Converting_Train_bson_into_TFrecords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDOlzpKYBUW7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to mount google drive in case you are loading the data from your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIPat3MwBcUq",
        "outputId": "83a9ce57-1eb3-4e24-af29-68dd8f8b5009"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "data_path = '/gdrive/MyDrive/UOH Assignment Dataset/cdiscount'\n",
        "os.chdir(data_path)\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6W-RMRfBgl2",
        "outputId": "ce99d59f-0547-4c0b-b4f4-3f270f3c849e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/UOH Assignment Dataset/cdiscount\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"../cdiscount/\"\n",
        "\n",
        "train_bson_path = os.path.join(data_dir, \"train.bson\")\n",
        "num_train_products = 7069896\n",
        "\n",
        "# train_bson_path = os.path.join(data_dir, \"train_example.bson\")\n",
        "# num_train_products = 82\n",
        "\n",
        "test_bson_path = os.path.join(data_dir, \"test.bson\")\n",
        "num_test_products = 1768182"
      ],
      "metadata": {
        "id": "vcyBP87uBkAw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import io\n",
        "import bson \n",
        "import tensorflow as tf\n",
        "# from PIL import Image  # or, whatever image library you prefer\n",
        "from skimage.io import imread \n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "# from subprocess import check_output\n",
        "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "# helper functions\n",
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def serialize_array(array):\n",
        "  array = tf.io.serialize_tensor(array)\n",
        "  return array\n"
      ],
      "metadata": {
        "id": "CGzFFnDrBU8F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def parse_single_image(image, label):\n",
        "  \n",
        "  #define the dictionary -- the structure -- of our single example\n",
        "  data = {\n",
        "        'height' : _int64_feature(image.shape[0]),\n",
        "        'width' : _int64_feature(image.shape[1]),\n",
        "        'depth' : _int64_feature(image.shape[2]),\n",
        "        'raw_image' : _bytes_feature(serialize_array(image)),\n",
        "        'label' : _int64_feature(label)\n",
        "    }\n",
        "  #create an Example, wrapping the single features\n",
        "  out = tf.train.Example(features=tf.train.Features(feature=data))\n",
        "\n",
        "  return out\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "DVq5odpYD9J_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_images_to_tfr_short(images, labels, filename:str=\"images\"):\n",
        "  filename= filename+\".tfrecords\"\n",
        "  writer = tf.io.TFRecordWriter(filename) #create a writer that'll store our data to disk\n",
        "  count = 0\n",
        "\n",
        "  for index in range(len(images)):\n",
        "\n",
        "    #get the data we want to write\n",
        "    current_image = images[index] \n",
        "    current_label = labels[index]\n",
        "\n",
        "    out = parse_single_image(image=current_image, label=current_label)\n",
        "    writer.write(out.SerializeToString())\n",
        "    count += 1\n",
        "\n",
        "  writer.close()\n",
        "  print(f\"Wrote {count} elements to TFRecord\")\n",
        "  return count"
      ],
      "metadata": {
        "id": "2A8beUj4EIdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = write_images_to_tfr_short(images_small, labels_small, filename=\"small_images\")\n"
      ],
      "metadata": {
        "id": "BblBpkhiEK8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = bson.decode_file_iter(open(train_bson_path, 'rb'))\n",
        "\n",
        "\n",
        "for c, d in enumerate(data):\n",
        "  n_img = len(d['imgs'])\n",
        "  for index in range(n_img):\n",
        "    img_raw = d['imgs'][index]['picture']\n",
        "    img = imread(io.BytesIO(img_raw))\n"
      ],
      "metadata": {
        "id": "taEBI_0EEUAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tfrecords_filename = 'train_TFrecords.tfrecords'\n",
        "# opts = tf.io.TFRecordOptions(compression_type = 'ZLIB')\n",
        "\n",
        "\n",
        "\n",
        "# # on my workstation it takes about 5 min per 100k entries, so should finish in about 6h\n",
        "z = 0 \n",
        "data = bson.decode_file_iter(open(train_bson_path, 'rb'))\n",
        "with tf.io.TFRecordWriter(tfrecords_filename) as writer:\n",
        "    for c, d in enumerate(data):       \n",
        "        n_img = len(d['imgs'])\n",
        "        for index in range(n_img):\n",
        "            img_raw = d['imgs'][index]['picture']\n",
        "            img = imread(io.BytesIO(img_raw))\n",
        "            height = img.shape[0]\n",
        "            width = img.shape[1]\n",
        "            depth= img.shape[2]\n",
        "            product_id = d['_id']\n",
        "            category_id = d['category_id'] \n",
        "            example = tf.train.Example(features=tf.train.Features(feature={\n",
        "                'height': _int64_feature(height),\n",
        "                'width': _int64_feature(width),\n",
        "                'depth': _int64_feature(depth),\n",
        "                'category_id': _int64_feature(category_id),\n",
        "                'product_id': _int64_feature(product_id),\n",
        "                'img_raw':_bytes_feature(img_raw)\n",
        "            }))\n",
        "            writer.write(example.SerializeToString())\n",
        "        z = z + 1\n",
        "        print(z)"
      ],
      "metadata": {
        "id": "pBZtCkZLDuhs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}