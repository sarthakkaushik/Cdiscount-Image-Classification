{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reading- Tfrecord File.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMn11GUjrIqGGTIb2csEkxn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthakkaushik/Cdiscount-Image-Classification/blob/main/Reading_Tfrecord_File.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0U2Q4JK0zak",
        "outputId": "9a9cfb21-93b0-4888-9ab0-33cd9f7239f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Code to mount google drive in case you are loading the data from your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "data_path = '/gdrive/MyDrive/UOH Assignment Dataset/cdiscount'\n",
        "os.chdir(data_path)\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyZm7UQO05Aq",
        "outputId": "3ddcd7c6-f2f5-4eb2-c88f-45544e902c02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/UOH Assignment Dataset/cdiscount\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, math, io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing as mp\n",
        "import bson\n",
        "import struct\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import tensorflow as tf\n",
        "\n",
        "from collections import defaultdict\n",
        "from tqdm import *\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../cdiscount\"]).decode(\"utf8\"))\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcgbCYmS0-TN",
        "outputId": "48c786b0-ab54-4efd-a7be-aa3f75d9b671"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "categories.csv\n",
            "category_names.csv\n",
            "file.h5\n",
            "sample_submission.csv\n",
            "test.bson\n",
            "train.bson\n",
            "train_example.bson\n",
            "train_images.csv\n",
            "train_offsets.csv\n",
            "train_TFrecords.tfrecords\n",
            "val_images.csv\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading Tfrecord file\n",
        "\n",
        "data_dir = \"../cdiscount/\"\n",
        "\n",
        "train_tfrecord_path = os.path.join(data_dir, \"train_TFrecords.tfrecords\")\n",
        "\n",
        "\n",
        "raw_dataset = tf.data.TFRecordDataset(train_tfrecord_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "znMkYFG51Jzz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for raw_record in raw_dataset.take(10):\n",
        "  print(repr(raw_record))"
      ],
      "metadata": {
        "id": "GNuPdGkR2uu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for raw_record in raw_dataset.take(1):\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(raw_record.numpy())\n",
        "  print(example)"
      ],
      "metadata": {
        "id": "IdJZY48p41Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_tfr_element(element):\n",
        "  #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
        "  data = {\n",
        "      'height': tf.io.FixedLenFeature([], tf.int64),\n",
        "      'width':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'depth':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'category_id':tf.io.FixedLenFeature([], tf.int64),      \n",
        "      'product_id':tf.io.FixedLenFeature([], tf.int64),\n",
        "      'img_raw' : tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "\n",
        "    \n",
        "  content = tf.io.parse_single_example(element, data)\n",
        "  \n",
        "  height = content['height']\n",
        "  width = content['width']\n",
        "  depth = content['depth']\n",
        "  label = content['category_id']\n",
        "  product_id = content['product_id']\n",
        "  img_raw = content['img_raw']\n",
        "  \n",
        "  \n",
        "  #get our 'feature'-- our image -- and reshape it appropriately\n",
        "  feature = tf.io.decode_raw(img_raw,tf.uint8,fixed_length=97200)\n",
        "  feature = tf.reshape(feature, shape=[height,width,depth])\n",
        "  return (feature, label)"
      ],
      "metadata": {
        "id": "C4VWwTIXiG12"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a dataset out of the parse elements, we simply leverage the tf.data API. We create a TFRecordDataset by pointing it to the TFRecord file on our disk and then apply our previous parsing function to every extracted Example. This returns a dataset:"
      ],
      "metadata": {
        "id": "I-WbwXSRi9OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_small(filename):\n",
        "  #create the dataset\n",
        "  dataset = tf.data.TFRecordDataset(train_tfrecord_path, num_parallel_reads=4)\n",
        "          # = tf.data.TFRecordDataset(train_tfrecord_path, compression_type = 'ZLIB')\n",
        "\n",
        "  #pass every single feature through our mapping function\n",
        "  dataset = dataset.map(\n",
        "      parse_tfr_element\n",
        "  )\n",
        "    \n",
        "  return dataset"
      ],
      "metadata": {
        "id": "ocVM4c6di8Ub"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can explore the content of our dataset by taking a single data point:\n"
      ],
      "metadata": {
        "id": "MPd60CCmjFoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_small = get_dataset_small(train_tfrecord_path)\n",
        "\n",
        "# for sample in dataset_small.take(1):\n",
        "#   print(sample[0].shape)\n",
        "#   print(sample[1].shape)"
      ],
      "metadata": {
        "id": "9Ctpitz7jGVu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset_small)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3Vd8xoSkmBJ",
        "outputId": "1c757f57-ff4d-4392-bd91-73a99421c59e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.MapDataset"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in dataset_small.take(1):\n",
        "    print(data,type(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwuVgZOspdXM",
        "outputId": "229c7eef-c2d1-403d-c1ca-e5b489c42019"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(180, 180, 3), dtype=uint8, numpy=\n",
            "array([[[255, 216, 255],\n",
            "        [224,   0,  16],\n",
            "        [ 74,  70,  73],\n",
            "        ...,\n",
            "        [117, 118, 119],\n",
            "        [120, 121, 122],\n",
            "        [130, 131, 132]],\n",
            "\n",
            "       [[133, 134, 135],\n",
            "        [136, 137, 138],\n",
            "        [146, 147, 148],\n",
            "        ...,\n",
            "        [ 11,  28, 241],\n",
            "        [178, 171,  50],\n",
            "        [142, 219, 131]],\n",
            "\n",
            "       [[ 12, 215, 166],\n",
            "        [215, 124,  36],\n",
            "        [167,  21,  36],\n",
            "        ...,\n",
            "        [175,  21, 197],\n",
            "        [ 75,  20, 155],\n",
            "        [246, 105, 107]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[  0,   0,   0],\n",
            "        [  0,   0,   0],\n",
            "        [  0,   0,   0],\n",
            "        ...,\n",
            "        [  0,   0,   0],\n",
            "        [  0,   0,   0],\n",
            "        [  0,   0,   0]],\n",
            "\n",
            "       [[  0,   0,   0],\n",
            "        [  0,   0,   0],\n",
            "        [  0,   0,   0],\n",
            "        ...,\n",
            "        [  0,   0,   0],\n",
            "        [  0,   0,   0],\n",
            "        [  0,   0,   0]],\n",
            "\n",
            "       [[  0,   0,   0],\n",
            "        [  0,   0,   0],\n",
            "        [  0,   0,   0],\n",
            "        ...,\n",
            "        [  0,   0,   0],\n",
            "        [  0,   0,   0],\n",
            "        [  0,   0,   0]]], dtype=uint8)>, <tf.Tensor: shape=(), dtype=int64, numpy=1000010653>) <class 'tuple'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FROM THE AUTHOR"
      ],
      "metadata": {
        "id": "YzmTLllcmwAF"
      }
    }
  ]
}